{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16e8aa44",
   "metadata": {},
   "source": [
    "í•™ìŠµìš© ì˜ì–´-í”„ë‘ìŠ¤ì–´ ë³‘ë ¬ ë¬¸ì¥ ë°ì´í„° ì¤€ë¹„\n",
    "ê°œë…: \n",
    "   - ì…ë ¥(ì˜ì–´)ê³¼ ì¶œë ¥(í”„ë‘ìŠ¤ì–´) ìŒìœ¼ë¡œ êµ¬ì„±\n",
    "   - ë””ì½”ë” ì…ë ¥ì—ëŠ” ì‹œì‘ í† í°(\\t), íƒ€ê²Ÿì—ëŠ” ì¢…ë£Œ í† í°(\\n) ì¶”ê°€\n",
    " ì„¤ëª…:\n",
    "   - input_texts: ì¸ì½”ë”ì— ì…ë ¥ë  ì˜ì–´ ë¬¸ì¥\n",
    "   - target_texts: ë””ì½”ë”ê°€ ìƒì„±í•´ì•¼ í•  í”„ë‘ìŠ¤ì–´ ë¬¸ì¥ (ì „ì²˜ë¦¬ í¬í•¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2fa86f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥:Hello                --> íƒ€ê²Ÿ : \tBonjour\n",
      "\n",
      "ì…ë ¥:How are you          --> íƒ€ê²Ÿ : \tComment allez-vous\n",
      "\n",
      "ì…ë ¥:Good morning         --> íƒ€ê²Ÿ : \tBonjour matin\n",
      "\n",
      "ì…ë ¥:Thank you            --> íƒ€ê²Ÿ : \tMerci\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "data_pairs = [\n",
    "    (\"Hello\", \"Bonjour\"),\n",
    "    (\"How are you\", \"Comment allez-vous\"),\n",
    "    (\"Good morning\", \"Bonjour matin\"),\n",
    "    (\"Thank you\", \"Merci\"),\n",
    "]\n",
    "# ì…ë ¥ê³¼ íƒ€ê²Ÿì„ ë¶„ë¦¬\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "for eng, fra in data_pairs:\n",
    "    input_texts.append(eng)\n",
    "    # ë””ì½”ë” ì…ë ¥ '\\t'(ì‹œì‘), ë””ì½”ë” ì¶œë ¥:'\\n'(ì¢…ë£Œ)\n",
    "    target_texts.append(f'\\t{fra}\\n')\n",
    "for i in range(len(input_texts)):\n",
    "    print(f'ì…ë ¥:{input_texts[i]:20s} --> íƒ€ê²Ÿ : {target_texts[i]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51b118e",
   "metadata": {},
   "source": [
    "- ë¬¸ì ë‹¨ìœ„ ì‚¬ì „(vocabulary) ìƒì„± ë° ì •ìˆ˜ ì¸ë±ìŠ¤ ë³€í™˜\n",
    " ê°œë…:\n",
    "    - ê° ë¬¸ìë¥¼ ê³ ìœ í•œ ì •ìˆ˜ë¡œ ë§¤í•‘\n",
    "    - ì…ë ¥ê³¼ íƒ€ê²Ÿì˜ ì‚¬ì „ì€ ë³„ë„ ê´€ë¦¬\n",
    "    - ì›-í•« ì¸ì½”ë”©ìœ¼ë¡œ ì‹ ê²½ë§ ì…ë ¥ í˜•íƒœ ìƒì„±\n",
    "- ì„¤ëª…:\n",
    "    - input_characters: ì˜ì–´ ë¬¸ì¥ì— ë“±ì¥í•˜ëŠ” ëª¨ë“  ê³ ìœ  ë¬¸ì\n",
    "    - target_characters: í”„ë‘ìŠ¤ì–´ ë¬¸ì¥ + íŠ¹ìˆ˜ í† í°(\\t, \\n)\n",
    "    - encoder_input_data: 3D ë°°ì—´ (ìƒ˜í”Œ, ì‹œí€€ìŠ¤ ê¸¸ì´, ë¬¸ì ì‚¬ì „ í¬ê¸°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9f42615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê³ ìœ  ì…ë ¥ ë¬¸ììˆ˜ : 19\n",
      "ê³ ìœ  íƒ€ê²Ÿ ë¬¸ììˆ˜ : 22\n",
      "ìµœëŒ€ ì…ë ¥ ë¬¸ì¥ê¸¸ì´ : 12\n",
      "ìµœëŒ€ íƒ€ê²Ÿ ë¬¸ì¥ê¸¸ì´ : 20\n",
      "# ìƒ˜í”Œ, ì‹œí€€ìŠ¤ ê¸¸ì´, ë¬¸ì ì‚¬ì „ í¬ê¸°\n",
      "(4, 12, 19)\n",
      "(4, 20, 22)\n",
      "(4, 20, 22)\n"
     ]
    }
   ],
   "source": [
    "# ì…ë ¥ê³¼ íƒ€ê²Ÿì˜ ê³ ìœ í•œ ë¬¸ì ìˆ˜ì§‘\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "# for text in input_texts:\n",
    "#     for char in text:\n",
    "#         input_characters.add(char)\n",
    "\n",
    "input_characters = { char for text in input_texts for char in text}\n",
    "target_characters = {char for target_texts in target_texts for char in target_texts}\n",
    "\n",
    "# ì •ë ¬í•´ì„œ ì¼ê´€ì„± í™•ë³´\n",
    "input_characters = sorted(list(input_characters))\n",
    "input_characters\n",
    "target_characters = sorted(list(target_characters))\n",
    "target_characters\n",
    "\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "num_encoder_tokens,num_decoder_tokens\n",
    "\n",
    "\n",
    "# ê°€ì¥ ê¸´ ë¬¸ì¥ ê¸¸ì´ ê³„ì‚°\n",
    "max_encoder_seq_length = max(len(txt) for txt in input_texts)\n",
    "max_decoder_seq_length = max(len(txt) for txt in target_texts)\n",
    "max_encoder_seq_length, max_decoder_seq_length\n",
    "\n",
    "# ë¬¸ì -> ì¸ë±ìŠ¤ ë§¤í•‘\n",
    "input_token_index = {char:i for i,char in enumerate(input_characters)}\n",
    "target_token_index = {char:i for i,char in enumerate(target_characters)}\n",
    "\n",
    "# ì¸ë±ìŠ¤ -> ë¬¸ì ì—­ë§¤í•‘(ì¶”ë¡ ì‹œ ì‚¬ìš©)\n",
    "reverse_input_token_index = { idx:char for char,idx in input_token_index.items()}\n",
    "reverse_target_token_index = { idx:char for char,idx in target_token_index.items()}\n",
    "\n",
    "# encoder_input_data : 3D ë°°ì—´(ìƒ˜í”Œ, ì‹œí€€ìŠ¤ ê¸¸ì´, ë¬¸ì ì‚¬ì „ í¬ê¸°)\n",
    "encoder_input_data = np.zeros(  (len(input_texts),max_encoder_seq_length,num_encoder_tokens),\n",
    "                              dtype='float32'  )\n",
    "decoder_input_data = np.zeros(  (len(input_texts),max_decoder_seq_length,num_decoder_tokens),\n",
    "                              dtype='float32'  )\n",
    "decoder_target_data = np.zeros(  (len(input_texts),max_decoder_seq_length,num_decoder_tokens),\n",
    "                              dtype='float32'  )\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    \n",
    "    for t, char in enumerate(target_text):\n",
    "    #    'decoder_input_data: ì „ì²´ íƒ€ê²Ÿ ì‹œí€€ìŠ¤ (ì‹œì‘ í† í° í¬í•¨)'\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        \n",
    "    #    'decoder_target_data: í•œ íƒ€ì„ìŠ¤í… ì•ì„  ì •ë‹µ (Teacher Forcingìš©)'\n",
    "    #    ë””ì½”ë” ì…ë ¥ \\tì•ˆë…•\n",
    "    #    ë””ì½”ë” ì¶œë ¥ ì•ˆë…•\\n\n",
    "    #    í•œ ìŠ¤í… ì‹œí”„íŠ¸ - Teacher Forcing\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    # hi\n",
    "    # \\t hello ë””ì½”ë” ì…ë ¥\n",
    "    # hello \\n ë””ì½”ë” ì¶œë ¥ - Teacher Focing í•œìŠ¤í…œ ì•ìœ¼ë¡œ ì´ë™\n",
    "print(f'ê³ ìœ  ì…ë ¥ ë¬¸ììˆ˜ : {num_encoder_tokens}')\n",
    "print(f'ê³ ìœ  íƒ€ê²Ÿ ë¬¸ììˆ˜ : {num_decoder_tokens}')\n",
    "print(f'ìµœëŒ€ ì…ë ¥ ë¬¸ì¥ê¸¸ì´ : {max_encoder_seq_length}')\n",
    "print(f'ìµœëŒ€ íƒ€ê²Ÿ ë¬¸ì¥ê¸¸ì´ : {max_decoder_seq_length}')\n",
    "print('# ìƒ˜í”Œ, ì‹œí€€ìŠ¤ ê¸¸ì´, ë¬¸ì ì‚¬ì „ í¬ê¸°')\n",
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)\n",
    "print(decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783bf98d",
   "metadata": {},
   "source": [
    "- LSTM ê¸°ë°˜ Seq2Seq ì¸ì½”ë”-ë””ì½”ë” í•™ìŠµ ëª¨ë¸ êµ¬ì¶•\n",
    " - ê°œë…:\n",
    "    - Encoder: ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ê³  ìµœì¢… ìƒíƒœ(h, c) ì¶œë ¥\n",
    "    - Decoder: Encoder ìƒíƒœë¥¼ ì´ˆê¸°ê°’ìœ¼ë¡œ ë°›ì•„ íƒ€ê²Ÿ ì‹œí€€ìŠ¤ ìƒì„±\n",
    "    - return_state=True: LSTM ë‚´ë¶€ ìƒíƒœ(h, c) ë°˜í™˜\n",
    "    - return_sequences=True: ëª¨ë“  íƒ€ì„ìŠ¤í… ì¶œë ¥\n",
    " - ì„¤ëª…:\n",
    "    - encoder_states: [h, c] (hidden state, cell state)\n",
    "    - decoder_lstm: ì´ˆê¸° ìƒíƒœë¡œ encoder_states ì „ë‹¬\n",
    "    - decoder_dense: Softmaxë¡œ ê° íƒ€ì„ìŠ¤í…ì˜ ë¬¸ì í™•ë¥  ë¶„í¬ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b83fdcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ—ï¸ ëª¨ë¸ êµ¬ì¡°:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"seq2seq_training\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"seq2seq_training\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_input       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_input       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">282,624</span> â”‚ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      â”‚            â”‚                   â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">285,696</span> â”‚ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      â”‚            â”‚ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      â”‚            â”‚ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_dense       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)  â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,654</span> â”‚ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_input       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_input       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     â”‚    \u001b[38;5;34m282,624\u001b[0m â”‚ encoder_input[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      â”‚            â”‚                   â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     â”‚    \u001b[38;5;34m285,696\u001b[0m â”‚ decoder_input[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      â”‚            â”‚ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      â”‚            â”‚ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m256\u001b[0m)]             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_dense       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)  â”‚      \u001b[38;5;34m5,654\u001b[0m â”‚ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">573,974</span> (2.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m573,974\u001b[0m (2.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">573,974</span> (2.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m573,974\u001b[0m (2.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "latent_dim = 256  # LSTM ì€ë‹‰ ì°¨ì› (ë‚´ë¶€ í‘œí˜„ í¬ê¸°)\n",
    "\n",
    "# ==================== Encoder ====================\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens), name='encoder_input')\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# encoder_outputsëŠ” ì‚¬ìš©í•˜ì§€ ì•Šê³ , ë‚´ë¶€ ìƒíƒœ(state_h, state_c)ë§Œ ë””ì½”ë”ë¡œ ì „ë‹¬\n",
    "# ì…ë ¥ì‹œí€€ìŠ¤ë¥¼ LSTMì— í†µê³¼ì‹œì¼œì„œ ë§ˆì§€ë§‰ ì€ë‹‰ìƒíƒœ(state_h)ì™€ ì…€ìƒíƒœ(state_c) ë°›ì•„ì„œ\n",
    "# ë‘ ìƒíƒœëŠ” ì…ë ¥ë¬¸ì¥ì˜ ì˜ë¯¸(context)ë¥¼ ì••ì¶•í•œ ë²¡í„° \n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# ==================== Decoder ====================\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name='decoder_input')\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "\n",
    "# ë””ì½”ë” ì´ˆê¸° ìƒíƒœë¡œ ì¸ì½”ë” ìµœì¢… ìƒíƒœ ì‚¬ìš© (ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬)\n",
    "# ì¸ì½”ë”ì˜ ìƒíƒœ(state_h, state_c)ë¥¼ ì´ˆê¸°ìƒíƒœë¡œ ë°›ì•„ì„œ ìì‹ ì˜ ì…ë ¥ decoder_inputsë¥¼ ê¸°ë°˜ìœ¼ë¡œ \n",
    "# ë‹¤ìŒë‹¨ì–´ë¥¼ ì˜ˆì¸¡ --> ê° ì‹œì ì˜ ì¶œë ¥ì€ Dense+softmax ê±°ì³ì„œ ë‹¨ì–´(ë¬¸ì) í™•ë¥ ë¶„í¬\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# ê° íƒ€ì„ìŠ¤í…ì—ì„œ ë¬¸ì í™•ë¥  ë¶„í¬ ìƒì„±\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "#  ==================== í•™ìŠµ ëª¨ë¸ ====================\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='seq2seq_training')\n",
    "\n",
    "print(\"\\nğŸ—ï¸ ëª¨ë¸ êµ¬ì¡°:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0711022",
   "metadata": {},
   "source": [
    "``` \n",
    " ëª©ì : Seq2Seq ëª¨ë¸ ì»´íŒŒì¼ ë° í•™ìŠµ ì‹¤í–‰\n",
    " ê°œë…:\n",
    "    - categorical_crossentropy: ë‹¤ì¤‘ í´ë˜ìŠ¤(ë¬¸ì ì‚¬ì „) ì†ì‹¤\n",
    "    - Teacher Forcing: decoder_input_dataëŠ” ì •ë‹µ ì‹œí€€ìŠ¤ ì „ì²´ ì œê³µ\n",
    "    - í•™ìŠµ ëª©í‘œ: decoder_target_data (í•œ íƒ€ì„ìŠ¤í… ì•ë‹¹ê¸´ ì •ë‹µ)\n",
    " ì„¤ëª…:\n",
    "    - optimizer='rmsprop': ìˆœí™˜ì‹ ê²½ë§ì— ì•ˆì •ì ì¸ ìµœì í™” ì•Œê³ ë¦¬ì¦˜\n",
    "    - epochs=100: ì‘ì€ ë°ì´í„°ì…‹ì´ë¯€ë¡œ ì¶©ë¶„í•œ ë°˜ë³µ í•„ìš”\n",
    "    - batch_size=2: ë©”ëª¨ë¦¬ íš¨ìœ¨ (ì‹¤ì œë¡œëŠ” ì „ì²´ 4ê°œ ìƒ˜í”Œ ì‚¬ìš©)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "796b835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history=model.fit(\n",
    "    [encoder_input_data, decoder_input_data],   #seq2seq\n",
    "    decoder_target_data,\n",
    "    batch_size = 2,\n",
    "    epochs = 500,\n",
    "    validation_split = 0.0, #ë°ì´í„°ì…‹ì´ ì‘ì•„ì„œ ë¶„í•  ì•ˆí•¨\n",
    "    verbose = 0     #0 ì¶œë ¥ ì•ˆí•˜ê³  1ì€ ê°„ë‹¨í•˜ê²Œ 2 ì¢€ ë” ì¶œë ¥\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a7d0c00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44999998807907104"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a979b92d",
   "metadata": {},
   "source": [
    "- í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•´ ì‹¤ì œ ë²ˆì—­ìš© ì¶”ë¡  ëª¨ë¸ êµ¬ì¶•\n",
    " í•µì‹¬ ê°œë…:\n",
    "    - Encoder ëª¨ë¸: ì…ë ¥ â†’ ë‚´ë¶€ ìƒíƒœ ì¶”ì¶œ\n",
    "    - Decoder ëª¨ë¸: ì´ì „ ìƒíƒœ + í˜„ì¬ ì…ë ¥ â†’ ë‹¤ìŒ ë¬¸ì ì˜ˆì¸¡\n",
    "    - ì¶”ë¡  ì‹œì—ëŠ” Teacher Forcing ì—†ì´ ìê¸° ì˜ˆì¸¡ì„ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©\n",
    "- ì„¤ëª…:\n",
    "    - encoder_model: ì…ë ¥ ë¬¸ì¥ â†’ [h, c] ìƒíƒœ ì¶œë ¥\n",
    "    - decoder_model: í•œ íƒ€ì„ìŠ¤í…ì”© ë°˜ë³µ ì‹¤í–‰\n",
    "    - ê° ìŠ¤í…ì—ì„œ ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ë¬¸ì ì„ íƒ (Greedy Decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d795b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder : ì¶”ë¡  ëª¨ë¸\n",
    "encoder_model = Model(encoder_inputs, encoder_states, name='encoder_inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cd1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder ì¶”ë¡  ëª¨ë¸\n",
    "# ì´ì „ íƒ€ì„ìŠ¤í…ì˜ ìƒíƒœë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ\n",
    "decoder_state_input_h = Input(shape=(latent_dim,), name='decoder_state_h')\n",
    "decoder_state_input_c = Input(shape=(latent_dim,), name='decoder_state_c')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "# LSTMì‹¤í–‰(ì´ì „ìƒíƒœ+í˜„ì¬ì…ë ¥)\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state= decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "# ë¬¸ì í™•ë¥  ë¶„í¬ ìƒì„±\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs]  + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states,\n",
    "    name = 'decoder_inference'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09175205",
   "metadata": {},
   "source": [
    "```\n",
    "ì…ë ¥ ë¬¸ì¥ì„ ë²ˆì—­í•˜ëŠ” ë””ì½”ë”© í•¨ìˆ˜ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸\n",
    " ê°œë…:\n",
    "    - Greedy Decoding: ë§¤ ìŠ¤í… ê°€ì¥ ë†’ì€ í™•ë¥  ë¬¸ì ì„ íƒ\n",
    "    - ì¢…ë£Œ ì¡°ê±´: '\\n' í† í° ìƒì„± ë˜ëŠ” ìµœëŒ€ ê¸¸ì´ ë„ë‹¬\n",
    "    - ìê¸°íšŒê·€ì  ìƒì„±: ì´ì „ ì˜ˆì¸¡ì„ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ë°˜ë³µ ì‚¬ìš©\n",
    " ì„¤ëª…:\n",
    "    1. Encoderë¡œ ì…ë ¥ ë¬¸ì¥ì˜ ìƒíƒœ ë²¡í„° ì¶”ì¶œ\n",
    "    2. ì‹œì‘ í† í°('\\t')ìœ¼ë¡œ Decoder ì‹œì‘\n",
    "    3. ë°˜ë³µ: í˜„ì¬ ë¬¸ì ì˜ˆì¸¡ â†’ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©\n",
    "    4. '\\n' ë§Œë‚˜ë©´ ì¢…ë£Œ\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3f7dbf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì…ë ¥ ë¬¸ì¥ì„ ë²ˆì—­í•˜ëŠ” ë””ì½”ë”© í•¨ìˆ˜\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    \"\"\"\n",
    "    ì…ë ¥ ì‹œí€€ìŠ¤(ì›-í•« ì¸ì½”ë”©)ë¥¼ ë°›ì•„ ë²ˆì—­ëœ ë¬¸ìì—´ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    # 1ë‹¨ê³„: Encoderë¡œ ìƒíƒœ ë²¡í„° ì¶”ì¶œ\n",
    "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
    "    \n",
    "    # 2ë‹¨ê³„: ë””ì½”ë” ì‹œì‘ í† í° ì¤€ë¹„ ('\\t')\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.0\n",
    "    \n",
    "    # 3ë‹¨ê³„: ë¬¸ìë¥¼ í•˜ë‚˜ì”© ìƒì„±\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        # í˜„ì¬ ë¬¸ì ì˜ˆì¸¡ + ë‹¤ìŒ ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value, verbose=0\n",
    "        )\n",
    "        \n",
    "        # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ë¬¸ì ì„ íƒ (Greedy)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_token_index[sampled_token_index]\n",
    "        \n",
    "        # ë¬¸ì ì¶”ê°€\n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        # ì¢…ë£Œ ì¡°ê±´ ì²´í¬\n",
    "        if sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "        \n",
    "        # ë‹¤ìŒ ìŠ¤í… ì¤€ë¹„: í˜„ì¬ ì˜ˆì¸¡ì„ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "        \n",
    "        # ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "        states_value = [h, c]\n",
    "    \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9c6505da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000272E139A7A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "ì…ë ¥ë¬¸ì¥ : Hello\n",
      "ì •ë‹µë¬¸ì¥ : Bonjour\n",
      "ëª¨ë¸ ì˜ˆì¸¡ : Bonjour\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ì…ë ¥ë¬¸ì¥ : How are you\n",
      "ì •ë‹µë¬¸ì¥ : Comment allez-vous\n",
      "ëª¨ë¸ ì˜ˆì¸¡ : Comment alllll\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ì…ë ¥ë¬¸ì¥ : Good morning\n",
      "ì •ë‹µë¬¸ì¥ : Bonjour matin\n",
      "ëª¨ë¸ ì˜ˆì¸¡ : Bonjour  maa\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ì…ë ¥ë¬¸ì¥ : Thank you\n",
      "ì •ë‹µë¬¸ì¥ : Merci\n",
      "ëª¨ë¸ ì˜ˆì¸¡ : Merci\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(len(input_texts)):\n",
    "    # ì›í•«ì¸ì½”ë”© ì…ë ¥ ì¶”ì¶œ\n",
    "    input_seq =  encoder_input_data[seq_index:seq_index+1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    \n",
    "    # ì‹œì‘/ì¢…ë£Œ í† í° ì œê±°\n",
    "    decoded_sentence = decoded_sentence.replace('\\t','').replace('\\n','')\n",
    "    print(f'ì…ë ¥ë¬¸ì¥ : {input_texts[seq_index]}')\n",
    "    print(f'ì •ë‹µë¬¸ì¥ : {target_texts[seq_index][1:-1]}')  # ì‹œì‘ ì¢…ë£Œí† í°ì œê±°\n",
    "    print(f'ëª¨ë¸ ì˜ˆì¸¡ : {decoded_sentence}')\n",
    "    print('-'*100)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "89cfe97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
