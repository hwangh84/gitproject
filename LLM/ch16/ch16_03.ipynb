{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f121b828",
   "metadata": {},
   "source": [
    "한국어 영화 리뷰 - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b05b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://drive.google.com/file/d/1KOKgZ4qCg49bgj1QNTwk1Vd29soeB27o/view?usp=sharing\n",
    "\n",
    "import pandas as pd\n",
    "url = \"https://drive.google.com/uc?id=1KOKgZ4qCg49bgj1QNTwk1Vd29soeB27o\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e65a916c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9424,) (2356,) (2945,)\n",
      "(9424,) (2356,) (2945,)\n"
     ]
    }
   ],
   "source": [
    "# rating 6 이상이면 긍정 라벨 생성 y로 저장\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# y를 생성해서 review 컬럼이 x 데이터 분할 데이터 개수 확인\n",
    "y = np.array([1 if value >= 6 else 0 for value in df.rating])  # 6 이상이면 1(긍정), 미만이면 0(부정)\n",
    "x = df['review']  # 리뷰 텍스트\n",
    "\n",
    "# 데이터셋을 학습 검증 평가로 나눈다 x_train x_val x_test\n",
    "\n",
    "X_, x_test, y_, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "x_train, x_val, y_train , y_val = train_test_split(X_, y_, test_size=0.2, random_state=42, stratify=y_)\n",
    "\n",
    "print(x_train.shape,x_val.shape, x_test.shape)\n",
    "print(y_train.shape,y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df08bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from datasets import load_metric # 2022 이후로 huggingface에서 deprecated evaluate\n",
    "# load_metric이 datasets에서 제거됨 - evaluate 라이브러리 사용\n",
    "import evaluate\n",
    "metric = evaluate.load('accuracy')\n",
    "\n",
    "# 필요 시 설치: pip install evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36dc15c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    '''\n",
    "    Args:\n",
    "        eval_pred : logits.labels를 가지고 있는 dataset\n",
    "    Returns:\n",
    "        accuracy\n",
    "    '''\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15a08aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 코드는 PyTorch의 사용자 정의 데이터셋(Dataset) 클래스를 정의합니다.\n",
    "# PyTorch에서 딥러닝 모델을 훈련할 때 데이터를 효율적으로 로드하고 처리하기 위해 사용됩니다.\n",
    "\n",
    "# `torch.utils.data.Dataset`을 상속받아 `OurDataset` 클래스를 만듭니다.\n",
    "# 이 클래스는 다음 세 가지 필수 메서드를 구현해야 합니다:\n",
    "\n",
    "# 1. `__init__(self, encodings, labels)`:\n",
    "#    - 데이터셋을 초기화하는 생성자입니다.\n",
    "#    - `encodings`: 입력 데이터(예: 텍스트 데이터의 토큰화된 인코딩)를 담고 있는 딕셔너리입니다.\n",
    "#      각 키는 'input_ids', 'attention_mask' 등과 같을 수 있으며, 값은 텐서 또는 리스트 형태입니다.\n",
    "#    - `labels`: 각 입력 데이터에 해당하는 레이블(정답)을 담고 있는 리스트 또는 텐서입니다.\n",
    "#    - 이 메서드에서는 전달받은 `encodings`와 `labels`를 클래스 인스턴스의 속성으로 저장합니다.\n",
    "\n",
    "# 2. `__getitem__(self, idx)`:\n",
    "#    - 특정 인덱스 `idx`에 해당하는 데이터 샘플을 반환하는 메서드입니다.\n",
    "#    - `item = {key: torch.tensor(val[idx].clone().detach()) for key, val in self.encodings.items()}`:\n",
    "#      `self.encodings` 딕셔너리에서 `idx`에 해당하는 값을 가져와 PyTorch 텐서로 변환합니다.\n",
    "#      `.clone().detach()`는 원본 데이터에 대한 참조를 끊고 독립적인 복사본을 만들어,\n",
    "#      데이터가 모델 훈련 중 의도치 않게 변경되는 것을 방지하고 메모리 효율성을 높일 수 있습니다.\n",
    "#    - `item['labels'] = torch.tensor(self.labels[idx])`:\n",
    "#      `self.labels`에서 `idx`에 해당하는 레이블을 가져와 PyTorch 텐서로 변환하여 `item` 딕셔너리에 추가합니다.\n",
    "#    - 최종적으로, 입력 데이터와 해당 레이블을 포함하는 딕셔너리 `item`을 반환합니다.\n",
    "\n",
    "# 3. `__len__(self)`:\n",
    "#    - 데이터셋의 전체 크기(샘플 수)를 반환하는 메서드입니다.\n",
    "#    - `self.labels`의 길이를 반환하여 데이터셋에 몇 개의 샘플이 있는지 알려줍니다.\n",
    "\n",
    "# 요약: 이 `OurDataset` 클래스는 토큰화된 텍스트 인코딩과 해당 레이블을 받아,\n",
    "# PyTorch `DataLoader`가 개별 샘플을 쉽게 가져올 수 있도록 표준화된 인터페이스를 제공합니다.\n",
    "# 이는 특히 Hugging Face Transformers 라이브러리와 같은 곳에서 모델 훈련을 위한 데이터 준비에 유용합니다.\n",
    "\n",
    "# 데이타셋 생성 클래스(상속)\n",
    "# __init__ __getitem__ __len__  \n",
    "# x,y 각각 텐서  y의 개수\n",
    "\n",
    "import torch\n",
    "class OurDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels    = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)  # CUDA 호환성을 위해 long 타입 명시\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "608e8a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안', '##녕', '##하', '##세', '##요', '.', '반', '##갑', '##습', '##니다', '.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-cased') #다국어 지원(한국어)\n",
    "print(tokenizer.tokenize(\"안녕하세요. 반갑습니다.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d72464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   101,   9521, 118741,  35506,  24982,  48549,    119,   9321, 118610,\n",
      "         119081,  48345,    119,    102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# `return_tensors=\"pt\"`는 토크나이저가 처리된 입력을 PyTorch 텐서 형식으로 반환하도록 지시합니다.\n",
    "# 다른 옵션으로는 `tf` (TensorFlow 텐서), `np` (NumPy 배열), 또는 `None` (Python 리스트) 등이 있습니다.\n",
    "inputs = tokenizer(\"안녕하세요. 반갑습니다.\", return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b10aacda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안', '##녕', '##하', '##세', '##요', '.', '반', '##갑', '##습', '##니다', '.']\n",
      "{'input_ids': [101, 9521, 118741, 35506, 24982, 48549, 119, 9321, 118610, 119081, 48345, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# 2022년 이후로는 Auto~~~~ 토크나이져와 모델을 사용하도록 권장(벤더사에서 업데이트시 유리)\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "print(tokenizer.tokenize(\"안녕하세요. 반갑습니다.\"))\n",
    "inputs = tokenizer(\"안녕하세요. 반갑습니다.\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bf21af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Trainer에 사용할 Argument 설정\u001b[39;00m\n\u001b[32m     27\u001b[39m training_args = TrainingArguments(\n\u001b[32m     28\u001b[39m     output_dir=\u001b[33m'\u001b[39m\u001b[33m./results\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     29\u001b[39m     num_train_epochs=\u001b[32m1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m     dataloader_drop_last=\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# 불완전한 배치 제거\u001b[39;00m\n\u001b[32m     39\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m trainer = \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_metrics\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m trainer.train()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\transformers\\trainer.py:455\u001b[39m, in \u001b[36mTrainer.__init__\u001b[39m\u001b[34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28mself\u001b[39m.compute_loss_func = compute_loss_func\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# Seed must be set before instantiating the model when using model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m enable_full_determinism(\u001b[38;5;28mself\u001b[39m.args.seed) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.full_determinism \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mset_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28mself\u001b[39m.hp_name = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[38;5;28mself\u001b[39m.deepspeed = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\transformers\\trainer_utils.py:105\u001b[39m, in \u001b[36mset_seed\u001b[39m\u001b[34m(seed, deterministic)\u001b[39m\n\u001b[32m    103\u001b[39m np.random.seed(seed)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     torch.cuda.manual_seed_all(seed)\n\u001b[32m    107\u001b[39m     \u001b[38;5;66;03m# ^^ safe to call this function even if cuda is not available\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\torch\\_compile.py:32\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     30\u001b[39m     fn.__dynamo_disable = disable_fn\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    630\u001b[39m prior = _maybe_set_eval_frame(callback)\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    634\u001b[39m     _maybe_set_eval_frame(prior)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\torch\\random.py:46\u001b[39m, in \u001b[36mmanual_seed\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcuda\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.cuda._is_in_bad_fork():\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmps\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.mps._is_in_bad_fork():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\torch\\cuda\\random.py:129\u001b[39m, in \u001b[36mmanual_seed_all\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m    126\u001b[39m         default_generator = torch.cuda.default_generators[i]\n\u001b[32m    127\u001b[39m         default_generator.manual_seed(seed)\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\torch\\cuda\\__init__.py:249\u001b[39m, in \u001b[36m_lazy_call\u001b[39m\u001b[34m(callable, **kwargs)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_lazy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m, **kwargs):\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    251\u001b[39m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[32m    252\u001b[39m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[32m    253\u001b[39m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[32m    254\u001b[39m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\torch\\cuda\\random.py:127\u001b[39m, in \u001b[36mmanual_seed_all.<locals>.cb\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[32m    126\u001b[39m     default_generator = torch.cuda.default_generators[i]\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     \u001b[43mdefault_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# mBERT + Trainer로 미세조정(Fine-Tuning)\n",
    "# AutoModelForSequenceClassification: 시퀀스 분류(예: 감성 분석, 스팸 감지)를 위한 사전 학습된 모델을 로드하는 데 사용됩니다.\n",
    "# TrainingArguments: Trainer 클래스에 전달될 훈련 관련 하이퍼파라미터 및 설정을 정의하는 데 사용됩니다.\n",
    "# Trainer: Hugging Face Transformers 라이브러리에서 모델 훈련 및 평가를 위한 고수준 API를 제공합니다.\n",
    "# AutoTokenizer: 사전 학습된 모델에 해당하는 토크나이저를 자동으로 로드하는 데 사용됩니다. 텍스트를 모델 입력 형식으로 변환합니다.\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 토큰화\n",
    "train_input = tokenizer(x_train.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "val_input = tokenizer(x_val.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "test_input = tokenizer(x_test.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "print(train_input.keys())\n",
    "\n",
    "# Dataset생성 (레이블을 리스트로 변환)\n",
    "train_dataset = OurDataset(train_input, y_train.tolist())\n",
    "val_dataset = OurDataset(val_input, y_val.tolist())\n",
    "test_dataset = OurDataset(test_input, y_test.tolist())\n",
    "\n",
    "# 분류모델 생성 - 토크나이저와 동일한 multilingual 모델 사용\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'bert-base-multilingual-cased', \n",
    "    num_labels=2  # 이진 분류이므로 2개 클래스\n",
    ")\n",
    "\n",
    "# Trainer에 사용할 Argument 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,  # 배치 크기 축소로 메모리 안정성 확보\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=100,  # warmup_steps 축소\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to='none',\n",
    "    dataloader_drop_last=True  # 불완전한 배치 제거\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b4bff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새 셀에 추가\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a91ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  데이타셋 생성 클래스(상속)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac05fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cfb8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
