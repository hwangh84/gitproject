{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8ac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bea54de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c8e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "# client = OpenAI(api_key = os.environ['OPENAI_KEY'])\n",
    "client = OpenAI()\n",
    "def ask_llm(prompt, model = 'gpt-5-nano', temp=1):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,    \n",
    "        temperature=temp,\n",
    "        messages=[{\n",
    "            'role':'user',\n",
    "            'content' : prompt\n",
    "        }] \n",
    "    )       \n",
    "    return response.choices[0].message.content   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7d704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. zero-shot Prompting\n",
    "# 예시없이 지시사항만 던지는것 - LLM의 기본기능\n",
    "prompt = \"이 문장의 감정을 분류해: '오늘 점심 메뉴가 품절이라 너무 슬퍼.'\"\n",
    "print(ask_llm(prompt,temp=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b59aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. few-shot Prompting\n",
    "# 이렇게 하는거야 라고 예시(Shot)를 몇개 보여줘서 성능을 높이는 기술\n",
    "prompt = \"\"\"\n",
    "단어를 이모지로 바꿔줘\n",
    "사과 -> 🍎\n",
    "자동차 -> 🚗\n",
    "고양이 -> 🐱\n",
    "비행기->\n",
    "\"\"\"\n",
    "print(ask_llm(prompt,temp=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Chain-of-Thought Prompting  Cot(생각의 사슬)\n",
    "prompt = \"\"\"\n",
    "질문 : 5개의 사과중 2개를 먹고 3개를 더 샀어. 몇개 남았지\n",
    "사과의 단가는 100원\n",
    "지급한 금액 : 1000원\n",
    "총 남은 사과의 개수를 세고 그리고 사과를 구입할때 드는 비용을 \n",
    "계산해서 거스름돈을 계산해줘\n",
    "계산은 먹은 사과와 남은 사과를 모두 포함한 금액\n",
    "마지막 출력은 전체 로직을 점검해서 오류가 있는지 확인하고 결과알려줘\n",
    "\"\"\"\n",
    "print(ask_llm(prompt,temp=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. self-Consistency(자기 일관성)\n",
    "# 한번만 묻지 않고 여러번(예 : 3번) 물어본 뒤 가장 많이 나온 답을 채택함\n",
    "question = '철수는 학교까지 10분 걸려, 왕복은 몇분 걸릴까?'\n",
    "answer = []\n",
    "for _ in range(3):\n",
    "    answer.append(ask_llm(question))\n",
    "print(f'수집된 답변들: ', answer)\n",
    "from collections import Counter\n",
    "counter = Counter(answer)\n",
    "counter.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Generate Knowlege Prompting(지식생성)\n",
    "# 바로 답하지 말고 관련된 지식을 먼저 생성한뒤에 그 지식을 바탕으로 답하게 됨\n",
    "# 1 지식생성\n",
    "knowledge = ask_llm('골프라는 스포츠에 대해 사실적인 지식 3가지만 나열해줘')\n",
    "print(f'[지식] : {knowledge}')\n",
    "# 2 단계 : 지식을 활용해 답변\n",
    "prompt = f\"\"\"\n",
    "다음 지식을 참고해서 '골프에서 홀인원이 왜 어려운지' 설명해줘.\n",
    "모든 답변은 한글로 작성\n",
    "[지식] : {knowledge}\n",
    "\"\"\"\n",
    "print(ask_llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94dc4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '골프에서 홀인원이 왜 어려운지 설명해줘'\n",
    "print(ask_llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b2e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Prompt Chaining(프롬프트 체이닝)\n",
    "# 복잡한 일을 한번에 시키지 않고 A작업의 결과를 B작업의 입력으로 넘겨주는 파이프라인\n",
    "# Step 1 : 주체 추출\n",
    "text = '이메일: 안녕하세요, 이번 주 금요일 회의는 2시로 변경되었습니다.'\n",
    "topic = ask_llm(f'다음 텍스트에서 핵심 주제만 단어로 뽑아줘 출력은 한글로:{text}')\n",
    "\n",
    "# step2 : 답장 작성\n",
    "reply = ask_llm(f\"'{topic}'에 대해 '알겠습니다'라는 정중한 답장 메일을 써줘\")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a118ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 Retrieval Augmented Generation(RAG 검색 증강 생성)\n",
    "# 이론 : LLM이 모르는 외부 데이터(회사문서등)을 찾아서 (Retrieval)프롬프트에 넣어주고 답하게 함\n",
    "\n",
    "# 가상의 검색된 문서\n",
    "retrieved_doc = \"문서내용: 우리 회사의 재택근무는 매주 수요일만 가능하다\"\n",
    "\n",
    "prompt = f'''\n",
    "아래[참조문서]를 기반으로 답변해, 문서에 없으면 모른다고 해.\n",
    "[참조문서] : {retrieved_doc}\n",
    "질문 : 재택근무는 언제 할 수 있어?\n",
    "'''\n",
    "print(ask_llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 Automatic Reasoning and Tool-use 자동 추론 및 도구 사용\n",
    "# LLM이 스스로 계산기나 검색엔진 같은 도구가 필요한지 판단하고 호출형식을 뱉어내는 것\n",
    "prompt = '''\n",
    "계산이 필요하면 [CALC: 수식] 이라고 출력해.\n",
    "질문 : 3452 * 192는 뭐야?\n",
    "'''\n",
    "response = ask_llm(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f781fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "너는 자동 도구 선택 시스템이야.\n",
    "다음과 같은 도구를 사용할 수 있어:\n",
    "\n",
    "1.계산기 -> [CALC : 수식]\n",
    "2.날씨 조회 ->[WEATHER : 도시명]\n",
    "3.일반질문 - >직접입력\n",
    "\n",
    "규칙:\n",
    "- 계산이 필요하면 CALC: ... 출력\n",
    "- 날씨 정보가 필요하면 WEATHER: 도시명 출력 도시명은 영문, json구조를 파싱해서 날씨정보를 읽어서\n",
    "사용자에게 친화적인 답변으로 변경\n",
    "- 그 외 는 일반적인 답변\n",
    "\n",
    "질문: 3458 * 256의 결과와 \n",
    "서울의 내일 날씨는 어때?\n",
    "\"\"\"\n",
    "\n",
    "def find_weather(CITY= 'Seoul'):    \n",
    "    API_KEY = os.environ['OPEN_WEATHER_KEY']\n",
    "    lat = 37.25\n",
    "    lon = 126.45\n",
    "    print(API_KEY)\n",
    "    CITY = 'Seoul'\n",
    "    url = f'https://api.openweathermap.org/data/2.5/weather?q={CITY}&appid={API_KEY}'\n",
    "    import requests\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "import re\n",
    "def process_response(text):\n",
    "    # 계산기\n",
    "    calc = re.findall(r'CALC:\\s*(.*)', text)\n",
    "    if calc:\n",
    "        expr = calc[0]  \n",
    "        print(f'계산기 expr = {expr}')      \n",
    "        return eval(expr)\n",
    "    # 날씨\n",
    "    weather = re.findall(r'WEATHER:\\s*(.*)', text)\n",
    "    if weather:\n",
    "        city = weather[0]\n",
    "        return find_weather(city)\n",
    "\n",
    "response = ask_llm(prompt)\n",
    "print(f'llm 출력 결과 : {response}')\n",
    "\n",
    "# for res in response.split('\\n'):\n",
    "#     process_response(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe2bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\[(\\w+)\\s*:\\s*([^\\]]+)\\]\"\n",
    "matches = re.findall(pattern, response)\n",
    "eval(matches[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafcfa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "(matches[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248fe039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "API_KEY = 'fdf46d9b90a6dce13b4e54db8621e743'\n",
    "lat = 37.25\n",
    "lon = 126.45\n",
    "print(API_KEY)\n",
    "CITY = 'Seoul'\n",
    "url = f'https://api.openweathermap.org/data/2.5/weather?q={CITY}&appid={API_KEY}'\n",
    "import requests\n",
    "response = requests.get(url)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d77798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Automatic Prompt Enginerr (APE)\n",
    "# 사람이 프롬프트는 짜는게 아니라 LLM에게 좋은 프롬프트를 짜줘 라고 시키는 것\n",
    "task = '고객의 리뷰에서 감정을 분석하는 작업'\n",
    "prompt = f'''\n",
    "나는 '{task}'을 하려고 해.\n",
    "이 작업을 수행하기에 가장 완벽한 프롬프트 지시문을 작성해줘 바로 사용할수 있도록 간결하게 작성\n",
    "'''\n",
    "best_prompt = ask_llm(prompt)\n",
    "print(best_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba16c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Active-Prompt\n",
    "# LLM이 답변하기 애매하거나 불확실한 문제를 찾아내서 사람에게 이것좀 가르쳐 주세요(예시추가) 라고 요청하는 방식\n",
    "# LLM에게 문제를 풀게하고 '확신도(Confidence score)를 묻는다 낮으면 그 문제를 few-shot에 예제로 추가\n",
    "\n",
    "# 프롬프트 생성\n",
    "import json\n",
    "def build_prompt(task:str,examples:list,query:str) -> str:\n",
    "    prompt = f'작업: {task}\\n\\n'\n",
    "    for ex in examples:\n",
    "        prompt += f\"예시 입력 : {ex['input']}\\n예시출력:{json.dumps({'answer':ex['answer'],\n",
    "                                        'confidence':ex.get('confidence',0.9)})}\\n\\n\"\n",
    "    prompt += f'입력:{query}\\njson 형식으로 answer ,confidence 반환'\n",
    "    return prompt\n",
    "\n",
    "def call_llm(prompt:str, model='gpt-5-nano') -> dict:\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages= [{'role':'user', 'content':prompt}]\n",
    "    )\n",
    "    text = resp.choices[0].message.content\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except:\n",
    "        return {'answer':text, 'confidence':0.0}\n",
    "# Active-prompt 루프\n",
    "def active_prompt(task:str, query:str, examples=None):\n",
    "    if examples is None:\n",
    "        examples = []\n",
    "    for i in range(4):\n",
    "        prompt = build_prompt(task, examples, query)\n",
    "        result = call_llm(prompt)\n",
    "        print(f\"\\nIteration : {i+1}: answer={result['answer']}, \\\n",
    "               confidence={result.get('confidence',0)}\")\n",
    "        if result.get('confidence',0) >= 0.75:\n",
    "            break\n",
    "        else:\n",
    "            # 낮은 confidence -> few shot 예제로 추가\n",
    "            examples.append({\"input\":query,'answer':result['answer'], \n",
    "                             \"confidence\":result.get('confidence',0)})\n",
    "    return result\n",
    "# 실행 : 명확한 문제\n",
    "task1= '숫자가 소수인지 판단'\n",
    "query1 = '97은 소수인가요?'\n",
    "res1 = active_prompt(task1,query1)\n",
    "print(res1)\n",
    "# 실행 : 애매한 문제\n",
    "task2= '주어진 문장을 더 정중하고 간결하게 바꿔주세요 너무 직설적이거나 모호하면 안됨'\n",
    "query2 = '이 프로젝트는 결과가 별로인거 같아요, 좀더 괜찮게 고쳐주세요'\n",
    "res2 = active_prompt(task2,query2)\n",
    "print(res2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5babe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 Directional Stimulus Prompting(방향성 자극)\n",
    "# 모델에게 구체적이 지시를 내리기전에 힌트(키워드)를 제공해서 답변의 방향을 유도\n",
    "article = '''\n",
    "로봇 산업이 '피지컬 인공지능(AI)'과 만나 새로운 확장기를 맞아가고 있다. 피지컬 AI란 물리적 세계를 인식·이해하고 직접 상호작용하는 행동형 AI를 의미한다. 기계의 '뇌'가 더 똑똑해질수록 제조·국방 등 핵심 분야에서 로봇이 유의미하게 쓰일 수 있다. 시장조사 업체 슈타티스타는 전 세계 피지컬 AI시장 규모가 올해 225억달러에서 2030년 643억달러로 성장할 것으로 전망했다.\n",
    "\n",
    "로봇은 피지컬 AI의 꽃으로 불린다. 미국과 중국 등 패권국은 이미 피지컬 AI와 결합한 로봇 산업을 국가적 '전략자산'으로 육성하고 있다. 특히 주요국들은 고령화·저출생에 따른 일손 부족, 인건비 상승의 흐름 속에서 제조업을 혁신할 키워드로 로봇에 주목하고 있다. 제조 강국인 한국이 주도권을 확보할 수 있는 분야로도 평가된다.\n",
    "\n",
    "이러한 가운데 로봇 분야 세계 최고 권위 학회이자 로봇 연구자 수만 명이 활동하는 커뮤니티인 전기전자공학자협회(IEEE) 산하 국제로봇·자동화학회(RAS)를 한국인이 이끌게 돼 주목된다. RAS 집행부는 지난달 학술대회를 열고 조규진 서울대 공대 교수를 차기 회장으로 선출했다. RAS 회장은 글로벌 로봇 분야의 학술·산업 어젠다를 조율하는 핵심 포지션이다.\n",
    "\n",
    "조 교수는 내년 1월부터 2027년 12월까지 회장 당선인으로 활동하며 2028년 1월부터 2029년 12월까지 RAS를 이끌게 된다. 로봇 업계와 학계에서는 한국 로봇 연구 커뮤니티의 국제 위상과 리더십이 한층 강화될 것이라는 기대가 나온다.\n",
    "\n",
    "조 교수는 생체모사 로봇, 소프트 로봇, 웨어러블 로봇 분야의 세계적인 석학이다. 그를 만나 로봇 학계 최신 트렌드와 RAS 회장 선출의 의미, 한국이 나아가야 할 방향 등을 들어봤다. 다음은 일문일답.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79117623",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "기사:{article}\n",
    "힌트(키워드) : 소프트웨어, AI\n",
    "위 힌트를 중심으로 기사를 요약해줘\n",
    "\"\"\"\n",
    "print(ask_llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bce07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 Program-Aided Language Models(PAL)\n",
    "# 수학문제나 날짜 계산은 말로 풀지 말고 파이썬 코드를 짜서 해결하도록 유도\n",
    "# LLM은 코딩을 더 잘함\n",
    "prompt = '''\n",
    "질문 : 2025년 11월 24일에서 90일 후는 무슨요일이야?\n",
    "이 문제를 해결하는 python코드를 작성하고 해당 코드를 이용해서 알려줘\n",
    "'''\n",
    "print(ask_llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df90380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 ReAct(Reason + Act)\n",
    "# 생각(Reason)하고 -> 행동(Act)하고 -> 관찰(Observation)하는 과정을 반복하면서 문제를 해결\n",
    "# 에이전트(Agent)의 기초\n",
    "prompt = '''\n",
    "질문 : 손흥민 나이에 10살을 더하면?\n",
    "다음 형식에 따라서 진행\n",
    "Thought: 손흥민의 생년월일을 검색한다\n",
    "Action : Search[손흥민의 생일]\n",
    "Observation : (검색결과 기디림)\n",
    "'''\n",
    "print(ask_llm(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e0d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 Reflexion(리플렉션 / 반성)\n",
    "# 모델이 틀린답을 냈을때 왜 틀렸는지 반성(Reflect)하고 다시 답을 출력 하는 과정\n",
    "wrong_answer = \"파이썬 리스트 추가 함수는 push() 입니다.\"\n",
    "prompt = f'''\n",
    "이전 답변 : {wrong_answer}\n",
    "이 답변을 틀렸어 파이썬 문법에 맞지 않어\n",
    "오류 원인을 분석(Reflection)하고 올바른 답을 수정해서 알려줘\n",
    "'''\n",
    "print(ask_llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a5fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 Multimodal Cot(멀티모달 Cot)\n",
    "# 텍스트뿐만 아니라 이미지를 함께 보면서 단계별로 추론하는 것\n",
    "client = OpenAI()\n",
    "# 로컬파일은 직접 지정 X\n",
    "uploaded = client.files.create(\n",
    "    file = open(r'C:\\LLM\\openai\\image.png', 'rb'),\n",
    "    purpose='vision'\n",
    ")\n",
    "file_id = uploaded.id\n",
    "\n",
    "reponse = client.chat.completions.create(\n",
    "    model = 'gpt-5-nano',\n",
    "    messages=[{\n",
    "        'role':'user',\n",
    "        'content':[\n",
    "            {'type':'text', 'text' : '이 사진의 상황을 단계별로 추론해서 설명해줘'},\n",
    "            {'type':'image_url', \n",
    "             'image_url':{'url':\"https://github.com/pia222sk20/LLM2/raw/main/openai/image.png\"} }\n",
    "        ]\n",
    "    }]\n",
    ")\n",
    "print(reponse.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ae0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17 Graph Prompting(그래프 프롬프팅)\n",
    "# 테이터를 텍스트가 아니라 그래프(노드와 연결관계) 형태로 설명하여 관계추론 능력을 높임\n",
    "prompt = '''\n",
    "- (철수) -- 친구 -- (영희)\n",
    "- (영희) -- 존경 -- (선생님)\n",
    "- (선생님) -- 제자 -- (철수)\n",
    "\n",
    "질문: 철수와 선생님의 관계를 그래프 구조를 보고 설명해줘 \n",
    "'''\n",
    "print(ask_llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890db837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서를 그래프구조 바꿔서 모델에 입력\n",
    "# 문서->지식 그래프->그래프 프롬프트->LLM->RAG\n",
    "prompt = '''\n",
    "회사 지식그래프(Knowledge Graph)\n",
    "\n",
    "(HR 부서) -- 관리 --> (채용프로세스)\n",
    "(채용프로세스) -- 포함 --> (이력서검토)\n",
    "(이력서검토) -- 검토자 --> (팀장)\n",
    "(이력서검토) -- 검토자 --> (HR매니저)\n",
    "\n",
    "사용자질문 : \"채용과정에서 HR 부서는 어떤 역활을 하나?\"\n",
    "\n",
    "지식그래프 기반으로 답변해줘\n",
    "'''\n",
    "print(ask_llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18 Meta-prompting(메타 프롬프팅)\n",
    "# 하나의 거대한 문제를 해결하기 위해서 llm 스스로 하위 프롬프트를 여러개 생성하고 관리하는 Meta(최상의) 기법 - 오케스트라 지휘자 - \n",
    "\n",
    "# 문제 :  중소기업이 AI 도입 전략을 세울때 핵심 단계를 알려줘\n",
    "# LLM 판단\n",
    "    # 전략 전문가\n",
    "    # 기술 전문가\n",
    "    # 예산: ROI 전문가\n",
    "# 3명이 필요하다고 하면 스스로 하위 프롬프트를 생성 --> 각각 실행 ->종합\n",
    "\n",
    "# 전문가 3명을 정의하도록 llm에게 요청\n",
    "meta_prompt = '''\n",
    "우리는 다음 문제를 해결하려고 한다\n",
    "중소기업이 AI 도입 전략을 세울때 핵심 단계를 알려줘\n",
    "\n",
    "이 문제를 해결하기 위해 필요한 전문가 3명을 정의하고\n",
    "각 전문가에 줄 개별 프롬프트를 만들어라\n",
    "\n",
    "출력형식:\n",
    "1. 전문가1 이름:\n",
    "프롬프트:\n",
    "2. 전문가2 이름:\n",
    "프롬프트:\n",
    "3. 전문가3 이름:\n",
    "프롬프트:\n",
    "'''\n",
    "print(f'메타 프롬프트를 생성.....')\n",
    "experts = ask_llm(meta_prompt)\n",
    "print(experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6ed5ddb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. 전문가1 이름: 중소기업 AI 전략 설계 전문가\\n프롬프트:\\n당신은 중소기업의 AI 도입 전략 설계 전문가다. 목표는 제한된 예산과 인력으로도 실행 가능한 “핵심 단계 로드맵”을 제시하는 것이다. 아래 요구사항을 반영해 8~12개의 핵심 단계로 구성된 로드맵을 만들어라.\\n- 각 핵심 단계에 포함될 항목: 단계명, 목적, 추천 산출물(템플릿/문서), 선행 조건(데이터/기술/인력), 예상 소요 기간(주), 이전 단계와의 의존 관계\\n- 우선순위 선정 프레임워크: 가치/비용/리스크 기반으로 사용 사례를 선별하는 방법 제시\\n- 빠른 성과를 위한 Quick Wins 시나리오 포함\\n- 데이터 준비, 기술 스택 선택, 거버넌스, 예산 및 ROI 추정 방법의 개략적 가이드 포함\\n- 리스크 관리: 흔한 실패 요인 5가지와 이를 방지하는 대책 제시\\n- 예시 적용: 제조업, 소매업, 서비스업 중 하나의 간단한 사례를 통해 맥락 설명\\n- 출력 형식은 항목별 목록으로, 각 항목은 숫자 표기로 구성되도록 해줘\\n- 필요 시 도식화 흐름(1-2문장)을 함께 포함해 전체 흐름을 이해시키게 해줘\\n\\n2. 전문가2 이름: 데이터 거버넌스 및 보안 전문가\\n프롬프트:\\n당신은 데이터 거버넌스와 보안 전문이다. 중소기업의 AI 도입에 필요한 데이터 측면의 핵심 체크리스트와 설계안을 제시하라.\\n- 포함 내용: 데이터 거버넌스 프레임워크(데이터 소유 및 책임, 정책, 표준), 데이터 품질 관리 계획(데이터 품질 지표, 메타데이터/데이터 계보), 데이터 인프라 요구사항(데이터 레이크/웨어하우스, 접속 제어, 암호화, 백업), 데이터 보안(접근 제어, 인증/권한 관리, 모니터링, 사고 대응), 개인정보 보호 및 규정 준수(PII/민감정보 처리, 지역별 규정), 공급망 데이터 계약 및 리스크 관리(벤더 데이터 처리 계약), 데이터 파이프라인 설계의 실현 가능성 및 우선순위, 성공 지표(KPI)와 운영 체계.\\n- 출력물 형식은 체크리스트, 도식화된 아키텍처 개요, 그리고 단계별 실행 가이드로 구성\\n- 중소기업 규모에 맞춘 현실적 예시와 우선순위 제시\\n- 데이터 초기 수집/정제부터 배포까지의 간단한 로드맹(데모/샘플 데이터 포함) 구성 제안도 포함\\n\\n3. 전문가3 이름: AI 구현 및 변화 관리 전문가\\n프롬프트:\\n당신은 AI 구현 및 변화 관리 전문이다. 중소기업이 AI를 실제로 도입하고 운영에 정착시키는 실행 가이드를 제공하라.\\n- 포함 내용: 파일럿에서 확대로 이어지는 단계별 추진 방식(단계별 목표, 산출물, 성공 기준), 이해관계자 매핑 및 커뮤니케이션 전략, 변화 관리 계획(저항 관리, 조직 역량 강화, 교육/훈련), 빠른 시범(Pilot) 설계와 확산 로드맹, PMO 구성 및 공급업체 관리, 모델 운영 및 성능 모니터링 체계, 예산/일정/리스크 관리\\n- 실행 산출물 예시: 프로젝트 계획 템플릿, 파일럿 설계 문서, KPI 대시보드 예시, 위험 관리 로그, 교육 자료 개요\\n- 애자일/반복적 실행 권장 및 도입 시나리오 제시\\n- 성공적 도입을 위한 조직 문화 변화와 사용자 채택 촉진 전략 포함'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ae9a3126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['다음은 제한된 예산과 인력으로도 실행 가능한 12단계의 핵심 로드맵입니다. 각 단계는 구체적 목표, 주요 활동, 기대 산출물, 권장 도구를 함께 제시해 바로 실행에 옮길 수 있도록 구성했습니다.\\n\\n1. 경영진 스폰서 확보 및 문제 정의\\n- 목표: AI 도입의 목표를 명확히 하고 1~2개의 고임팩트 use case를 선정\\n- 주요 활동: 경영진 워크숍 개최, 비즈니스 문제를 1~2문장으로 정의, 성공지표(KPI) 설정\\n- 산출물: 우선순위 문제 목록, 선택된 MVP(use case 1개)와 KPI\\n- 권장 도구/전략: 간단한 프레이밍 도구(RICE/ICE), 기존 회의록 활용\\n\\n2. 데이터 현황 진단 및 소유 체계 확립\\n- 목표: 활용 가능한 데이터 원천과 책임자를 파악\\n- 주요 활동: 데이터 인벤토리 작성, 데이터 소유자/접근 권한 파악, 개인정보/보안 이슈 목록화\\n- 산출물: 데이터 소유자 맵, 데이터 소스 목록, 보안/프라이버시 기본 가이드\\n- 권장 도구/전략: 스프레드시트 기반 데이터 카탈로그, 간단한 데이터 맵\\n\\n3. 데이터 품질 및 거버넌스 기본 구축\\n- 목표: 데이터 품질 문제를 빠르게 해결할 기반 마련\\n- 주요 활동: 기본 정제 규칙 수립(결측치 처리, 중복 제거, 포맷 통일), 품질 대시보드 시범 운영\\n- 산출물: 데이터 품질 개선 로드맹, 샘플링된 품질 리포트\\n- 권장 도구/전략: Python/pandas로 간단한 스크립트, 무료 ETL 도구로 시범 구성\\n\\n4. MVP 후보 use case 설계 및 선택\\n- 목표: 1개 핵심 use case로 최소한의 기능을 구현하는 MVP 정의\\n- 주요 활동: 데이터 준비 계획 확정, 모델링 접근법 결정(노코드/로우코드 vs 코딩), 평가 지표 확정\\n- 산출물: MVP 설계 문서, 평가 지표, 성공 조건\\n- 권장 도구/전략: 로우코드/노코드 도구 또는 파이썬 기반 간단 프로토타입\\n\\n5. 인프라 및 도구 선택\\n- 목표: 비용 효율적이고 확장 가능한 도구 조합 선택\\n- 주요 활동: 클라우드 무료 티어 활용 여부 점검, 보안/로그 정책 초안 작성, 라이선스 검토\\n- 산출물: 도구 목록과 예산 가이드, 초기 운영 가이드\\n- 권장 도구/전략: 무료 티어가 있는 클라우드(IaaS/PaaS), 오픈소스 라이브러리, 간단한 배포 플랫폼\\n\\n6. 데이터 파이프라인 설계 및 구현\\n- 목표: 데이터가 원활하게 흐르고 모델에 공급되는 파이프라인 구축\\n- 주요 활동: 데이터 수집/변환/저장 파이프라인 설계, 이벤트 트리거 정의, 샘플 데이터로 엔드투엔드 테스트\\n- 산출물: 파이프라인 문서, 샘플 파이프라인 실행 로그\\n- 권장 도구/전략: Airbyte/Singer 등 경량 ETL, 간단한 dbt 또는 스크립트 기반 변환\\n\\n7. 모델 개발 및 평가\\n- 목표: 베이스라인 모델과 비교 가능한 성능 확보\\n- 주요 활동: 데이터 분할(학습/검증/테스트), 베이스라인 모델 구축, 교차검증 및 성능 비교\\n- 산출물: 평가 리포트, 재현 가능한 모델 스펙\\n- 권장 도구/전략: Python + scikit-learn, 필요 시 AutoML 도구의 무료 tier 활용\\n\\n8. 배포 설계 및 운영 모니터링\\n- 목표: 안전하고 지속 가능한 배포와 운영 관리 체계 수립\\n- 주요 활동: API 엔드포인트 또는 배치 프로세스로의 배포, 모니터링 대시보드 구성, 알림 정책 수립\\n- 산출물: 운영 가이드, SLA 초안, 모니터링 대시보드\\n- 권장 도구/전략: 간단한 API 배포(Cloud Run/AWS Lambda 등), 무료 모니터링 도구\\n\\n9. 변화 관리 및 내부 역량 강화\\n- 목표: 조직 내 AI 도입에 대한 수용성 확보와 역량 확충\\n- 주요 활동: 이해관계자 교육, 내부 챔피언 네트워크 구축, 도메인별 사용 가이드 작성\\n- 산출물: 교육 자료, 내부 사례 문서\\n- 권장 도구/전략: 짧은 교육 세션, 사내 커뮤니케이션 채널 활용\\n\\n10. 초기 가치 실현 및 확장 로드맵 확정\\n- 목표: MVP를 통한 실제 가치 측정 및 확장 방향 정립\\n- 주요 활동: KPI 모니터링, 피드백 루프 운영, 확장 후보 도메인 목록 및 우선순위 정리\\n- 산출물: ROI/가치 창출 리포트, 확장 로드맵\\n- 권장 도구/전략: 대시보드 기반 실적 시각화\\n\\n11. 보안, 개인정보보호 및 규정 준수 강화\\n- 목표: 리스크 최소화 및 법적 준수 확보\\n- 주요 활동: 접근 제어 정책 강화, 로그 보관/보안 점검, 필요시 데이터 익명화 또는 마스킹\\n- 산출물: 보안 정책 문서, 컴플라이언스 체크리스트\\n- 권장 도구/전략: IAM 구성, 데이터 마스킹 도구 최소한의 도입\\n\\n12. 정기 거버넌스 점검 및 재투자 의사 결정\\n- 목표: 학습한 교훈 반영 및 예산/우선순위 재조정\\n- 주요 활동: 분기별 성과 리뷰, 비용-편익 재계산, 백로그 재정렬\\n- 산출물: 분기 리뷰 보고서, 업데이트된 백로그\\n- 권장 도구/전략: 간단한 OKR/PM 도구, 워크샵 방식의 재계획 세션\\n\\n실행 팁\\n- 시작은 \"하나의 문제, 하나의 데이터 소스, 하나의 모델\"로 MVP를 빠르게 만들어 증명합니다.\\n- 가능한 한 무료 티어/오픈소스 도구를 활용하고, 초기 비용이 들어가는 경우에도 3개월 내 회수를 목표로 계획합니다.\\n- 데이터 품질과 거버넌스를 먼저 다져야 모델 성능이 과도하게 떨어지지 않습니다.\\n- 역할 분담은 최소한의 인력으로도 가능하도록, 한 사람이 데이터/모델 개발과 운영 모두를 겸하도록 초기에는 작은 팀 구성으로 시작합니다.\\n- 빠른 피드백 루프를 구축해 비용 대비 가치를 신속히 확인하고, 확장 때의 우선순위를 명확히 합니다.\\n\\n원하시면 귀사 산업(예: 제조, 소매, 서비스)과 현재 데이터 상황에 맞춘 맞춤형 12단계 세부 실행 가이드와 예시 KPI, 도구 목록을 더 구체적으로 만들어 드리겠습니다.',\n",
       " '다음은 중소기업(SME)이 AI 도입 시 데이터 측면에서 반드시 갖춰야 할 핵심 체크리스트와 실무 설계안입니다. 현장 적용 가능하도록 간결한 형태로 정리했고, 우선순위와 산출물 예시를 함께 제시합니다.\\n\\n1) 핵심 체크리스트 (카테고리별; 실행 주기와 산출물 포함)\\n\\nA. 데이터 전략/거버넌스\\n- 목표 정의와 정책 체계화\\n  - 목표: AI 활용 목적 및 데이터 거버넌스 목표를 명확히 설정\\n  - 실행 주기: 1회 수립 후 1년 단위 점검\\n  - 담당자: 최고 데이터 책임자(CDO) 또는 데이터 거버넌스 책임자\\n  - 산출물: 데이터 거버넌스 정책서, 데이터 분류 규정, 개인정보 처리방침\\n- 데이터 소유자 및 스튜어드 지정\\n  - 실행 주기: 상시 갱신\\n  - 산출물: 역할/책임 매트릭스(Data Owner, Data Steward 정의)\\n\\nB. 데이터 카탈로그/메타데이터 관리\\n- 자산 인벤토리 및 분류 체계 구축\\n  - 실행 주기: 분기별 업데이트\\n  - 산출물: 데이터 자산 목록, 분류 표준, 데이터 흐름(Lineage) 초안\\n- 메타데이터 표준화\\n  - 실행 주기: 상시 관리\\n  - 산출물: 메타데이터 모델, 스키마 표준\\n\\nC. 데이터 품질 관리\\n- 품질 지표 정의 및 자동화\\n  - 실행 주기: 월간 점검\\n  - 산출물: 품질 지표 대시보드, 품질 규칙 세트\\n- 데이터 프로파일링 및 정합성 검사\\n  - 실행 주기: 배치/실시간 파이프라인에서 지속 수행\\n  - 산출물: 데이터 품질 리포트, 에러 로그\\n\\nD. 데이터 보안/개인정보 보호\\n- 암호화와 키 관리\\n  - 실행 주기: 상시 관리\\n  - 산출물: 암호화 정책, 키 관리 정책\\n- 접근 제어와 인증/권한 관리\\n  - 실행 주기: 신규 사용자/권한 변경 시마다\\n  - 산출물: IAM 정책, RBAC/ABAC 모델 문서\\n- 비밀 관리 및 감사\\n  - 실행 주기: 상시\\n  - 산출물: 비밀 관리 절차, 감사 로그 정책\\n- 익명화/가명화 정책\\n  - 실행 주기: 데이터 공유 전마다\\n  - 산출물: 프라이버시 보호 설계서, DPIA/PIA 기록\\n\\nE. 데이터 저장소 아키텍처\\n- 저장소 계층 정의(원천/레이크/웨어하우스)\\n  - 실행 주기: 1회 설계 후 필요 시 점검\\n  - 산출물: 데이터 아키텍처 다이어그램, 저장소 정책\\n- 데이터 파이프라인 아키텍처\\n  - 실행 주기: 파이프라인 확장 시마다\\n  - 산출물: ETL/ELT 설계 문서, 데이터 품질 게이트 정의\\n\\nF. 데이터 수집/통합 및 품질 보강\\n- 소스 식별과 계약/합의\\n  - 실행 주기: 신규 소스 도입 시\\n  - 산출물: 소스 목록, 데이터 수집 계약/데이터 품질 합의서\\n- 데이터 변환/정제 로직 관리\\n  - 실행 주기: 변경 시마다\\n  - 산출물: ETL/ELT 규칙 문서, 코드 저장소 버전 관리\\n\\nG. 데이터 접근/공유 및 협력 파트너 관리\\n- 내부/외부 공유 정책\\n  - 실행 주기: 정책 업데이트 시\\n  - 산출물: 데이터 공유 정책, 거래/서비스 수준 합의(SLA) 템플릿\\n- 익명화 수준에 따른 접근 제어\\n  - 실행 주기: 신규 공유 시\\n  - 산출물: 공유 허용 범위 매핑표\\n\\nH. 개인정보 보호 및 규정 준수\\n- 지역별 규정 대응(DPA/데이터 로케이션 포함)\\n  - 실행 주기: 법령 개정 시\\n  - 산출물: DPIA/PIA 보고서, 개인정보 처리 기록\\n- 데이터 최소수집 원칙 및 데이터 주기적 삭제 정책\\n  - 실행 주기: 정책/데이터 생애주기 변경 시\\n  - 산출물: 데이터 최소수집 가이드, 보존기간 정책\\n\\nI. ML 데이터 사이클 및 편향 관리\\n- 라벨링 가이드라인과 학습용 데이터 관리\\n  - 실행 주기: 모델 개발/재학습 시\\n  - 산출물: 라벨링 표준, 데이터 셋 관리 정책\\n- 모델 학습 데이터의 투명성/재현성 확보\\n  - 실행 주기: 모델 업데이트 시\\n  - 산출물: 데이터 버전 관리 정책, 샘플 데이터 셋 보관\\n\\nJ. 운영 및 사고 대응\\n- 로그·모니터링·관계자 교육\\n  - 실행 주기: 상시\\n  - 산출물: 사고 대응 계획, DR/BCP 문서\\n- 데이터 손실/이상 탐지 프로세스\\n  - 실행 주기: 이벤트 발생 시\\n  - 산출물: 사건대응 기록 양식\\n\\nK. 교육 및 문화\\n- 보안/거버넌스 교육 이수\\n  - 실행 주기: 분기/반기\\n  - 산출물: 교육 이수 현황, 교육 자료\\n\\nL. 벤더/외부 협력사 관리\\n- 공급망 보안 및 데이터 공유 계약 점검\\n  - 실행 주기: 계약 체결/갱신 시\\n  - 산출물: 벤더 보안 요구사항 체크리스트, SCC 초안\\n\\nM. 기본 우선순위 제안\\n- High: 데이터 분류 정책, 데이터 소유자/스튜어드 지정, 접근 제어, DPIA/PIA, 암호화/감사 로그, 데이터 품질 기본 체계\\n- Medium: 데이터 카탈로그 초기 구축, 파이프라인 기본 품질 게이트, 익명화 정책\\n- Low: 고급 데이터 마켓플레이스 기능, 복잡한 데이터 공유 계약의 자동화 확대\\n\\n참고: 각 항목의 실행 주기, 책임자, 산출물은 귀사 규모와 현황(클라우드 여부, 데이터 양, 규정 대상 지역)에 맞춰 조정합니다.\\n\\n2) 데이터 측면 설계안(실무 로드맷)\\n\\nA. 목표 정의와 범위\\n- AI 도입 목표와 핵심 사용사례를 명확히 정의\\n- 데이터 거버넌스의 범위와 우선순위 사용사례를 선정\\n- 제약사항(예: 예산, 보안, 규정) 명시\\n\\nB. 거버넌스 프레임워크 구성\\n- 역할: Data Owner, Data Steward, Security Lead, Compliance Officer, IT 운영자\\n- 정책: 데이터 분류, 데이터 공유, 보안, 개인정보보호, 품질 관리 정책\\n- 의사결정 룰: 변경 관리, 위험 수용 한도, 정책 승인 절차\\n\\nC. 데이터 아키텍처 설계\\n- 원천 데이터 소스 식별 및 분류\\n- 데이터 저장소 계층: 원천/레이크/웨어하우스의 역할 정의\\n- 데이터 파이프라인 흐름\\n  - 원천 데이터 수집(실시간/배치) → 데이터 정제·표준화 → 품질 게이트 → 피처 저장소/데이터 카탈로그 → 모델 학습용/운영용 데이터 제공\\n- 메타데이터/데이터 라인리지 체계 수립\\n- 데이터 품질 검사 포인트 정의(수집 시점, 전처리 시점, 저장 시점)\\n\\nD. 보안 및 프라이버시 설계\\n- 암호화(전송/저장)와 키 관리(KMS/해당 벤더 도구)\\n- 접근 제어: 최소권한 원칙, RBAC/ABAC, SSO 연동\\n- 비밀관리: API 키/토큰 관리 솔루션\\n- 감사 로그 및 모니터링: 이벤트 로깅, 보안 이벤트 모니터링\\n- 개인정보 보호: 데이터 분류 수준에 따른 익명화/가명화 규칙, DPIA 수행\\n- 데이터 공유 시 계약 및 기술적 보호장치 적용\\n\\nE. 데이터 관리 운영 모델\\n- 데이터 거버넌스 운영 프로세스(정책 갱신, 위험 관리, 주기 리뷰)\\n- 데이터 품질 관리 프로세스(프로파일링, 정합성 검사, 품질 대시보드)\\n- 데이터 카탈로그 유지 관리 및 메타데이터 품질 관리\\n- 모델 개발/운영에 대한 MLOps 체계 기본 설계(데이터 버전 관리, 모델 레지스트리, drift 모니터링)\\n\\nF. 실행 로드맷(마일스톤)\\n\\n- 0-3개월(1차 PoC/기초 구축)\\n  - 데이터 인벤토리 완료, 주요 데이터 소스 분류\\n  - 거버넌스 정책 초안 및 책임자 지정\\n  - 기본 데이터 파이프라인(수집+정제+저장) 구현\\n  - 간이 데이터 카탈로그/메타데이터 저장소 구축\\n  - 기본 보안 제어(암호화, 접근 제어, 감사 로그) 구현\\n  - DPIA 간단 버전 및 개인정보 관리 정책 수립\\n- 3-6개월(안정화 및 확장)\\n  - 품질 게이트 고도화, 데이터 품질 대시보드 구축\\n  - 피처 저장소 또는 데이터 카탈로그 강화\\n  - 1-2개 핵심 사용사례에 대해 모델 학습용 데이터 준비\\n  - 내부/외부 공유 정책 시범 적용(데이터 익명화 적용 범위 확대)\\n- 6-12개월(운영화 및 MLOps 도입)\\n  - 모델 개발/배포 파이프라인(ML 엔트리 포인트) 구성\\n  - 데이터 버전 관리 및 실시간 모니터링 체계 도입\\n  - 컴플라이언스 자동화(주기 DPIA 갱신, 로그/감사 자동화)\\n  - 추가 데이터 소스 도입 및 라인리지 정교화\\n\\nG. PoC(파일럿) 추천 구성\\n- 사용사례: 고객 데이터 예측/물류 예측 등 비즈니스에 직접적인 ROI가 있는 1~2개 사례\\n- 데이터: 최소한의 핵심 데이터 셋 확보(PII 최소화 버전)\\n- 성공지표(KPI): 데이터 품질 개선도, 모델 성능(정확도/평균오차), 보안/규정 준수 여부, 운영 비용 절감 비율\\n\\nH. 산출물 예시(템플릿)\\n- 데이터 거버넌스 정책서: 목표, 범위, 역할, 정책 조항, 변경 관리 절차\\n- 데이터 분류표: 자산명, 데이터 민감도, 보존 기간, 익명화 여부\\n- DPIA 템플릿: 시스템 설명, 데이터 흐름, 위험 식별, 완화 조치, 승인\\n- 데이터 카탈로그 스키마 예시: 자산ID, 이름, 소유자, 분류, 라인리지, 품질 지표, 접근 정책\\n- 접근 요청 양식: 요청자 정보, 데이터 자산, 목적, 기간, 승인 경로\\n- 보안 로그 정책: 로그 수집 항목, 보관 기간, 접근 권한 관리\\n- 데이터 품질 대시보드 설계 문서: 지표 정의, 수집 방법, 임계값, 알림 규칙\\n- 데이터 보관/삭제 정책: 보존 기간, 삭제 절차, 백업 정책\\n\\n3) SME에 맞춘 실무 팁\\n\\n- 시작은 작게, 확장은 체계적으로\\n  - PoC 1~2개 핵심 사용사례 중심으로 파일럿하고, 성공 지표를 명확히 정의합니다.\\n- 클라우드 활용 권장\\n  - 비용 예측이 쉽고 보안/거버넌스 도구를 손쉽게 조합할 수 있습니다. 예산이 한정될 땐 “필수 도구+필수 정책” 우선순위로 단계적 도입이 효과적입니다.\\n- 데이터 품질이 Ai의 열쇠\\n  - 데이터 품질, 카탈로그, 라인리지 체계가 AI 성능과 직결되므로 초기 투자에서 우선순위를 높게 두십시오.\\n- 프라이버시/보안은 설계 단계부터\\n  - Privacy by design 원칙을 프로젝트 초기부터 반영하고, DPIA를 프로젝트 전 과제에 연결합니다.\\n- 재사용 가능한 모듈화\\n  - 파이프라인, 모델 학습/배포 파이프라인은 모듈화해 재사용성과 재현성을 확보합니다.\\n- 문서화와 교육의 축적\\n  - 정책, 표준, 가이드라인, 로그 모듈화된 문서로 남겨 두고, 모든 구성원이 이해하는 교육 체계를 만듭니다.\\n\\n4) 도구·기술(선택지; SME에 적합한 오픈소스/클라우드 옵션의 예시)\\n- 데이터 카탈로그/메타데이터: DataHub, Apache Atlas, Amundsen(오픈소스) 또는 클라우드 네이티브 카탈로그\\n- 데이터 품질: Great Expectations, 경향성 프로파일링 도구\\n- ETL/ELT 파이프라인: Apache NiFi, Airbyte, Matillion(클라우드 기반), Stitch\\n- 데이터 저장소: AWS S3/Azure Blob 또는 GCS를 통한 스토리지 계층\\n- 데이터 웨어하우스/레이크하우스: Snowflake, BigQuery, Databricks Lakehouse(필요 시)\\n- 피처 저장소/ML 운영: Feast(피처 저장소, 선택사항)\\n- 모델 관리/실행: MLflow, DVC, Kubeflow(필요시)\\n- 보안/비밀 관리: HashiCorp Vault, 클라우드 키 관리 서비스(KMS)\\n- 모니터링/로깅: Prometheus/Grafana, ELK/EFK 스택\\n\\n5) 시작을 위한 간단한 체크리스트(오늘 바로 시작하기)\\n- 현황 진단: 모든 데이터 자산 목록과 소유자, 보안 수준 1차 점검\\n- 데이터 분류 표준 확정: 민감 데이터 식별 및 기본 익명화 규칙\\n- 최소한의 데이터 파이프라인 구성: 원천 → 정제 → 저장의 간단한 흐름 설계\\n- 접근 관리 정책 초안 작성: 1차 RBAC 모델 및 신규 사용자 onboarding 절차\\n- DPIA/개인정보 관리 계획 수립: 간단한 DPIA 템플릿 생성 및 저장\\n- 초기 PoC 선정과 KPI 합의: 1~2개 핵심 사용사례, 성공 지표 정의\\n\\n필요하시면 귀사의 산업 분야(제조/물류/서비스 등), 데이터 규모, 지역 규정(GDPR/개인정보 보호법 등)과 클라우드 여부에 맞춘 구체적인 체크리스트 템플릿, 설계 도큐먼트 샘플 템플릿을 맞춤형으로 제공해 드리겠습니다. 원하시는 영역(SLA, 예산 규모, 도입 기간 등)을 알려주시면 그에 맞춰 더욱 구체적인 실행 로드맷과 산출물 예시를 드리겠습니다.',\n",
       " \"다음은 중소기업이 AI를 실제로 도입하고 운영에 정착시키기 위한 실행 가이드입니다. 비전 수립에서부터 거버넌스, 데이터 준비, 파일럿, 운영화까지 단계별로 actionable한 내용과 실무 템플릿을 함께 제공합니다.\\n\\n1) 실행의 기본 원칙\\n- 비즈니스 문제 중심: AI를 도입하는 목적이 무엇인지 한 줄로 정의하고, 그 문제를 해결하기 위한 구체적 성공지표(KPI)를 설정합니다.\\n- 경영진의 분명한 스폰서십: 최고 의사결정권자의 지속적 지원과 예산 확보가 실행의 생명선입니다.\\n- 데이터와 인프라의 현실성: 현재 보유 데이터의 양과 품질, 보안/프라이버시 요건을 먼저 평가합니다.\\n- 변화 관리(Change Management) 우선: 기술만으로는 못합니다. 업무 재설계, 의사결정 프로세스 변화, 구성원의 학습이 필수입니다.\\n- 점진적 확장: 한두 개의 가치를 빠르게 창출하는 파일럿 → 교훈 반영 → 재사용 가능한 플랫폼으로 확장.\\n\\n2) 실행 프레임(4단계 접근)\\n- 단계 A. 전략+거버넌스 설계\\n  - 문제 정의, 성공지표(KPI), 예산, 일정, 리스크 목록 확정\\n  - AI 운영 거버넌스 팀 구성: AI 챔피언(또는 AI PM), 데이터 소유자, 데이터 엔지니어, ML 엔지니어, 보안/개인정보 담당, 변경 관리 담당\\n- 단계 B. 데이터 준비와 인프라 진단\\n  - 데이터 맵 작성: 어떤 데이터가 있고, 어디에 저장되며, 품질은 어떤지 파악\\n  - 보안, 프라이버시, 법적 준수 확인(PDPA 등 국내 규정)\\n  - 파일럿에 필요한 최소한의 인프라 확보(데이터 파이프라인, 간단한 모델 개발 환경)\\n- 단계 C. 파일럿 설계 및 실행\\n  - 해결하려는 문제를 1~2개로 축약하고 성공 기준을 명확히\\n  - 짧은 주기(4–8주) 스프린트로 빠른 학습과 피드백 확보\\n  - 재사용 가능한 컴포넌트(데모 데이터셋, 파이프라인, 평가 지표) 구축\\n- 단계 D. 운영화 및 확장\\n  - 파일럿에서 얻은 교훈을 반영해 플랫폼화(재사용 가능한 템플릿, 모듈화된 파이프라인)\\n  - 추가 부문으로 확장하고, AI 운영의 모니터링·거버넌스 강화를 지속\\n\\n3) 실행 로드맵(100일 플랜)\\n- 0–30일: 전략 확정 + 데이터 점검 + 파일럿 선정\\n  - 비즈니스 문제 1건 정의, KPI 2개 설정\\n  - 데이터 카탈로그 작성 시작, 데이터 품질 이슈 목록화\\n  - 벤더/도구 선택 여부 초안 수립(내부 개발 vs 외부 SaaS)\\n- 31–60일: 파일럿 설계 및 초기 구현\\n  - 파일럿 Use Case 1의 상세 설계, 성공 기준 확정\\n  - 데이터 파이프라인 구축, 모델 개발/학습 시작\\n  - Change Management 계획 수립(커뮤니케이션, 교육, 역할 재설계)\\n- 61–90일: 파일럿 실행 및 평가, 운영화 준비\\n  - 파일럇 결과 측정, 목표 달성 여부 확인\\n  - 성공 시 재사용 가능한 템플릿(프로젝트 템플릿, 모델 성능 대시보드) 확보\\n  - 운영 팀 구조 확보, 보안/규정 점검, 확장 로드맵 확정\\n- 90일 이후: 확장 로드맵 실행\\n  - 추가 기능/부문으로 확장된 파일럿 설계\\n  - 조직 전반의 AI 성숙도 관리 체계 구축\\n\\n4) 핵심 산출물/템플릿(실전용)\\n- RACI 매트릭스 예시\\n  - 열: 기능/활동(예: 데이터 수집, 모델 개발, 모니터링, 변경 관리)\\n  - 행: 역할(예: AI 챔피언, 데이터 소유자, 데이터 엔지니어, 보안 담당, 경영진)\\n  - 내용 예시: 데이터 소유자 - 책임/승인; AI 챔피언 - 주도; 보안 담당 - 자격요건 확인 등\\n- 데이터 맵 템플릿(간단한 텍스트 예시)\\n  - 데이터 자산: 고객 DB, 주문 시스템, 피드백 로그\\n  - 소스/저장 위치: ERP, CRM, 데이터 레이크\\n  - 민감도: 일반/민감/특수(민감 데이터의 예: 결제정보)\\n  - 품질 이슈: 누락/정합성/중복 여부\\n- KPI 프레임 예시\\n  - 운영 효율: 처리 시간 감소 (%) / 인력 대체 비율\\n  - 품질: 오류율 감소, 정확도/정확성 점수\\n  - 매출/고객: 신제품 매출 증가, 고객 만족도 점수\\n  - 비용: 총 비용 절감, ROI\\n- 데이터 품질 체크리스트\\n  - 데이터 누락 여부, 중복 여부, 포맷 일관성, 시간 동기화 여부\\n- 보안/프라이버시 체크리스트\\n  - 데이터 최소화 원칙, 접근권한 관리, 로그 보관 정책, 감사 로그\\n  - 외부 벤더 사용 시 계약상의 데이터 처리 및 보안 조항 확인\\n- 샘플 사용 사례 정의\\n  - 문제: 고객 문의 대응 시간 단축\\n  - 입력/출력: 입력(문의 내용), 출력(자동 응답 또는 에이전트 핸드오프)\\n  - 성공 기준: 응답 시간 X% 감소, 문의 해결율 Y% 증가\\n\\n5) 3가지 초보자용 실전 사용 사례(낮은 리스크, 빠른 가치 창출)\\n- 사례 A: 고객 문의 자동 응대 챗봇\\n  - 목표: 초도 응답 시간 단축, 1차 대응 자동화\\n  - 필요 데이터: 자주 묻는 질문 데이터, 고객 기록\\n  - 기대 효과: 상담 대기 시간 감소, 1차 문의 자동화 비율 증가\\n- 사례 B: 재고/수요 예측으로 운영 비용 절감\\n  - 목표: 재고 최적화, 재고 비용 감소\\n  - 필요 데이터: 판매 기록, 프로모션 일정, 공급 리드타임\\n  - 기대 효과: 과잉 재고 감소, 품절 비용 감소\\n- 사례 C: 문서 자동 분류 및 처리 속도 향상\\n  - 목표: 문서 분류 자동화로 처리 시간 단축\\n  - 필요 데이터: 계약서/청구서/업무 문서 샘플\\n  - 기대 효과: 수작업 분류 시간 감소, 처리 오류 감소\\n\\n6) 데이터 준비와 기술 선택의 실무 포인트\\n- 데이터 준비\\n  - 데이터 품질 관리 체계 수립: 주기적 QC, 이슈 관리\\n  - 데이터 거버넌스: 데이터 소유자, 데이터 카탈로그, 접근 제어\\n  - 개인정보/민감정보 관리: 최소화 원칙, 익명화/가명화 적용 가능성 평가\\n- 기술 선택(빌드 vs 바이)\\n  - 빌드형: 고유한 비즈니스 규칙이나 데이터가 많은 경우 적합\\n  - 솔루션형(SaaS/LLM 활용): 빠른 시제품 제작 및 운영 효율성에 강점\\n  - 기본 구성: 데이터 파이프라인, 모델 개발/학습 환경, 모델 모니터링, 로그/감사\\n  - 재사용성 확보: 모듈화된 파이프라인, 특징 저장소(feature store) 도입 고려\\n\\n7) 운영화 및 거버넌스(지속 가능성 확보)\\n- 운영 모델\\n  - AI 운영 책임자(또는 AI PM) 주도, 데이터 소유자/보안 담당의 협업 체계\\n  - 모델 모니터링: 성능 drift, 입력 데이터 분포 변화 탐지, 보안 및 악용 여부 모니터링\\n  - 모델 리트레이닝 정책: 주기/사건 기반 리트레이닝 규정\\n- 변화 관리\\n  - 이해관계자 맵핑: 주요 부서별 영향도 분석\\n  - 커뮤니케이션 플랜: 목표, 기대효과, 일정, 역할 재정의에 대한 정기 커뮤니케이션\\n  - 역량 강화: 초급·중급 교육 로드맵, 실무 워크숍, 내부 사례 공유\\n  - 업무 재설계: AI 도입에 따라 업무 흐름 재정의 및 KPI 재설정\\n- 규정·보안\\n  - 법적 준수: 개인정보보호법(PDPA) 등 국내 규정 준수 확인\\n  - 계약 관리: 데이터 처리 위탁, 데이터 보관 기간, 벤더 보안 인증 요구\\n  - 감사/로그: 모델 운영 로그, 액세스 로그의 보관 및 감사 가능성 확보\\n\\n8) 예산과 성공 측정\\n- 예산 구성(대략적 범주)\\n  - 인력 및 교육: AI 전문 인력, 데이터 엔지니어, Change Manager 교육\\n  - 도구/인프라: 데이터 파이프라인 도구, 모델 학습/배포 플랫폼, 모니터링 도구\\n  - 컨설팅/외부 지원: 파일럿 설계·평가, 보안 감사\\n  - 예산 규모는 소기업의 매출 규모, 목표 KPI, 복잡도에 따라 크게 다름(작은 파일럿 수만큼 비용도 상대적임)\\n- 성공 지표(KPI 예시)\\n  - 시간/비용 절감: 처리 시간 감소율, 인력 재배치의 비용 절감\\n  - 품질: 정확도/오류율 개선\\n  - 비즈니스 영향: 매출/신규 고객, 고객 만족도 상승\\n  - 운영 안정성: 시스템 가동 시간, 실패/에러율 감소\\n\\n9) 리스크 및 대응 전략\\n- 데이터 품질 실패 및 불확실성\\n  - 해결: 데이터 품질 관리 강화, 시범적 적용으로 시작\\n- 보안/프라이버시 위반 위험\\n  - 해결: 최소화 원칙, 암호화/접근 제어, 감사 로그\\n- 변화 저항 및 인재 이탈\\n  - 해결: 이해관계자 참여, 교육과 보상, 성공 사례 공유\\n- 벤더 의존성/호환성 문제\\n  - 해결: 모듈화된 아키텍처, 중복 가능성 평가, 계약서에 이식성 조항 포함\\n\\n10) 실전 체크리스트(간단한 시작용)\\n- 0주차\\n  - 문제 정의와 KPI 확정? 경영진 서명 확보?\\n  - 데이터 소유자 및 보안 담당자 지정?\\n  - 파일럿 후보 문제 1건 선정?\\n- 1–2주차\\n  - 데이터 맵 작성 시작, 데이터 품질 이슈 목록화\\n  - 파일럿 성공 기준 구체화\\n- 3–4주차\\n  - 데이터 파이프라인 설계/구성 착수\\n  - 벤더/도구 평가 문서 작성\\n- 5–8주차\\n  - 파일럿 모델 개발 및 초기 검증\\n  - 변경 관리 계획(교육/커뮤니케이션) 실행 시작\\n- 9–12주차\\n  - 파일럿 결과 평가/확정, 운영화 로드맵 수립\\n  - 확장 대상 부문과 우선순위 결정\\n\\n11) 실행에 도움이 되는 실전 팁\\n- 가치를 먼저 보여주는 작은 성공 사례를 만들어야 지속 가능성이 큽니다. 4–8주 간의 짧은 파일럿에서 20~50% 수준의 개선이 가능하도록 목표를 설정해 보세요.\\n- 데이터 품질은 대개 가장 큰 제약입니다. 데이터 수집 주체와 품질 책임자를 명확히 하고, 초기에는 품질 이슈를 빠르게 해결하는 '작은 승리'를 우선하십시오.\\n- 변화 관리에 투자하십시오. 기술 도입이 성공하려면 업무 프로세스의 재설계와 구성원 교육이 병행되어야 합니다.\\n- 법적/윤리적 위험을 먼저 점검하십시오. 국내 규정(PDPA 등) 준수 여부를 프로젝트 시작 전에 확인하는 것이 안전합니다.\\n- 재사용 가능한 구성 요소를 만들어 두면 확장 속도가 빨라집니다. 파이프라인, 평가 지표, 대시보드 등을 모듈화해 다른 부문으로 쉽게 확장합니다.\\n\\n필요하면 이 가이드를 바탕으로 다음을 제공해 드릴 수 있습니다:\\n- 귀사 상황에 맞춘 90일 파일럿 설계서(Use Case 1–2건 구체화)\\n- RACI 매트릭스, 데이터 맵 샘플, KPI 대시보드 템플릿(텍스트 포맷)\\n- 귀사 산업별 구체적m KPI 예시 및 실행 체크리스트\\n- 국내 규정 준수 체크리스트와 보안 가이드\\n\\n원하시는 업종(제조, 유통, 서비스 등)이나 현재 데이터 상황(데이터의 양·질, 시스템 현황)을 알려주시면 더 구체적으로 맞춤형 실행 계획과 템플릿을 작성해 드리겠습니다.\"]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "exp_prompts = re.findall(r'프롬프트:\\s*(.*)', experts)\n",
    "# 각 전문가 llm 호출\n",
    "result = [ ask_llm(prompt) for prompt in exp_prompts]\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0134216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음은 중소기업이 AI 도입 전략을 체계적으로 수립할 때 참고할 핵심 단계들입니다. 각 단계는 목적, 주요 활동, 산출물, 권장 도구/전략으로 구성되어 실행에 바로 옮길 수 있도록 정리했습니다.\n",
      "\n",
      "1) 경영진 스폰서 확보 및 문제 정의\n",
      "- 목표: AI 도입의 목적을 명확히 하고 1~2개의 고임팩트 use case를 선정\n",
      "- 주요 활동: 경영진 워크숍 개최, 비즈니스 문제를 1~2문장으로 정의, 성공지표(KPI) 설정\n",
      "- 산출물: 우선순위 문제 목록, 선택된 MVP(use case 1개)와 KPI\n",
      "- 권장 도구/전략: 간단한 프레이밍 도구(RICE/ICE), 기존 회의록 활용\n",
      "\n",
      "2) 데이터 현황 진단 및 소유 체계 확립\n",
      "- 목표: 활용 가능한 데이터 원천과 책임자를 파악\n",
      "- 주요 활동: 데이터 인벤토리 작성, 데이터 소유자/접근 권한 파악, 개인정보/보안 이슈 목록화\n",
      "- 산출물: 데이터 소유자 맵, 데이터 소스 목록, 보안/프라이버시 기본 가이드\n",
      "- 권장 도구/전략: 스프레드시트 기반 데이터 카탈로그, 간단한 데이터 맵\n",
      "\n",
      "3) 데이터 품질 및 거버넌스 기본 구축\n",
      "- 목표: 데이터 품질 문제를 빠르게 해결할 기반 마련\n",
      "- 주요 활동: 기본 정제 규칙 수립(결측치 처리, 중복 제거, 포맷 통일), 품질 대시보드 시범 운영\n",
      "- 산출물: 데이터 품질 개선 로드맹, 샘플링된 품질 리포트\n",
      "- 권장 도구/전략: Python(pandas)으로 간단 스크립트 작성, 무료 ETL 도구로 시범 구성\n",
      "\n",
      "4) MVP 후보 use case 설계 및 선택\n",
      "- 목표: 1개 핵심 use case로 최소한의 기능을 구현하는 MVP 정의\n",
      "- 주요 활동: 데이터 준비 계획 확정, 모델링 접근법 결정(노코드/로우코드 vs 코딩), 평가 지표 확정\n",
      "- 산출물: MVP 설계 문서, 평가 지표, 성공 조건\n",
      "- 권장 도구/전략: 로우코드/노코드 도구 또는 Python으로 간단 프로토타입\n",
      "\n",
      "5) 인프라 및 도구 선택\n",
      "- 목표: 비용 효율적이고 확장 가능한 도구 조합 선택\n",
      "- 주요 활동: 클라우드 무료 티어 활용 여부 점검, 보안/로그 정책 초안 작성, 라이선스 검토\n",
      "- 산출물: 도구 목록과 예산 가이드, 초기 운영 가이드\n",
      "- 권장 도구/전략: 무료 티어가 있는 클라우드, 오픈소스 라이브러리, 간단한 배포 플랫폼\n",
      "\n",
      "6) 데이터 파이프라인 설계 및 구현\n",
      "- 목표: 데이터가 원활하게 흐르고 모델에 공급되는 파이프라인 구축\n",
      "- 주요 활동: 데이터 수집/변환/저장 파이프라인 설계, 이벤트 트리거 정의, 샘플 데이터로 엔드투엔드 테스트\n",
      "- 산출물: 파이프라인 문서, 샘플 파이프라인 실행 로그\n",
      "- 권장 도구/전략: Airbyte/Singer 등 경량 ETL, 간단한 dbt 또는 스크립트 기반 변환\n",
      "\n",
      "7) 모델 개발 및 평가\n",
      "- 목표: 베이스라인 모델과 비교 가능한 성능 확보\n",
      "- 주요 활동: 데이터 분할(학습/검증/테스트), 베이스라인 모델 구축, 교차검증 및 성능 비교\n",
      "- 산출물: 평가 리포트, 재현 가능한 모델 스펙\n",
      "- 권장 도구/전략: Python + scikit-learn, 필요 시 무료 AutoML 도구 활용\n",
      "\n",
      "8) 배포 설계 및 운영 모니터링\n",
      "- 목표: 안전하고 지속 가능한 배포와 운영 관리 체계 수립\n",
      "- 주요 활동: API 엔드포인트/배치 프로세스 배포, 모니터링 대시보드 구성, 알림 정책 수립\n",
      "- 산출물: 운영 가이드, SLA 초안, 모니터링 대시보드\n",
      "- 권장 도구/전략: 간단한 API 배포(Cloud Run/AWS Lambda 등), 무료 모니터링 도구\n",
      "\n",
      "9) 변화 관리 및 내부 역량 강화\n",
      "- 목표: 조직 내 AI 도입에 대한 수용성 확보와 역량 확충\n",
      "- 주요 활동: 이해관계자 교육, 내부 챔피언 네트워크 구축, 도메인별 사용 가이드 작성\n",
      "- 산출물: 교육 자료, 내부 사례 문서\n",
      "- 권장 도구/전략: 짧은 교육 세션, 사내 커뮤니케이션 채널 활용\n",
      "\n",
      "10) 초기 가치 실현 및 확장 로드맵 확정\n",
      "- 목표: MVP를 통한 실제 가치 측정 및 확장 방향 정립\n",
      "- 주요 활동: KPI 모니터링, 피드백 루프 운영, 확장 후보 도메인 목록 및 우선순위 정리\n",
      "- 산출물: ROI/가치 창출 리포트, 확장 로드맵\n",
      "- 권장 도구/전략: 대시보드 기반 실적 시각화\n",
      "\n",
      "11) 보안, 개인정보보호 및 규정 준수 강화\n",
      "- 목표: 리스크 최소화 및 법적 준수 확보\n",
      "- 주요 활동: 접근 제어 정책 강화, 로그 보관/보안 점검, 필요시 데이터 익명화 또는 마스킹\n",
      "- 산출물: 보안 정책 문서, 컴플라이언스 체크리스트\n",
      "- 권장 도구/전략: IAM 구성, 데이터 마스킹 도구 최소한의 도입\n",
      "\n",
      "12) 정기 거버넌스 점검 및 재투자 의사 결정\n",
      "- 목표: 학습한 교훈 반영 및 예산/우선순위 재조정\n",
      "- 주요 활동: 분기별 성과 리뷰, 비용-편익 재계산, 백로그 재정렬\n",
      "- 산출물: 분기 리뷰 보고서, 업데이트된 백로그\n",
      "- 권장 도구/전략: 간단한 OKR/PM 도구, 워크샵 방식의 재계획 세션\n",
      "\n",
      "실행 팁(간단 요약)\n",
      "- 하나의 문제, 하나의 데이터 소스, 하나의 모델에서 시작해 빠르게 증명합니다.\n",
      "- 가능한 한 무료 티어/오픈소스 도구를 활용하고, 3개월 내 회수 가능하도록 계획합니다.\n",
      "- 데이터 품질과 거버넌스를 먼저 다져야 모델 성능 저하를 막을 수 있습니다.\n",
      "- 역할은 최소 인력으로 겸임 가능한 구조로 시작해 점차 확장합니다.\n",
      "- 빠른 피드백 루프를 통해 비용 대비 가치를 신속히 확인하고 우선순위를 조정합니다.\n",
      "\n",
      "원하시면 이 핵심 단계를 바탕으로 산업별 맞춤형 실행 가이드(예: 제조, 유통, 서비스), KPI 예시, 템플릿(RACI, 데이터 맵, KPI 대시보드) 등을 함께 제공해 드리겠습니다. 필요 영역이나 상황(데이터 규모, 규정 위치, 클라우드 여부 등)을 알려주시면 보다 구체적으로 정리해 드립니다.\n"
     ]
    }
   ],
   "source": [
    "final_prompt = f'''\n",
    "다음은 3명의 전문가가 낸 의견이야\n",
    "\n",
    "1.{result[0]}\n",
    "2.{result[1]}\n",
    "3.{result[2]}\n",
    "\n",
    "위 내용을 종합해서 \n",
    "중소기업이 AI 도입 전략을 세울때 핵심 단계를 정리해서 작성해\n",
    "단계적으로, 명확하게, 문장이나 문맥에 어색함 없이, 한글로 작성해\n",
    "'''\n",
    "print(ask_llm(final_prompt))\n",
    "\n",
    "# 1. Meta LLM\n",
    "# 2. Sub  LLM\n",
    "# 3. Aggregator(종합 단계)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094b6720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
