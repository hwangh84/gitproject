{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7cddf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthe cat sat on the mat\\nRNN 계열 : 왼쪽 -> 오른쪽 멀리떨어진 단어들은 서로 영향을 주고 받기 어려움\\n\\nThe cat that the boy who lived here adopted is sleeping\\ncat VS sleeping\\n\\nself-attention\\nQ : 찾고 싶은 정보\\nK : 가진 정보\\nV : 최종 전달할 정보\\n\\n비교대상        유사도              의미\\ncat vs the      낮음                the 의미없음\\ncat vs cat      높음                자기자신\\ncat vs sat      중간                동사와 연결\\ncat vs on       낮음                on 전치사...\\ncat vs mat      낮음                의미적으로 멀다\\n\\nsoftmax로 중요도 확률처럼 변경      유사도를 가중치로 변환\\n단어            가중치\\nthe             0.05\\nsat             0.3\\nmat             0.05\\ncat             0.6\\n\\ncat이 보는 시점은\\nQuery(cat) -> compare with -> Key(the) -> key(cat) -> key(sat)\\n\\n가중치\\nthe : 01  cat: 0.7   sat : 0.2\\n출력 : 0.1*value(the) + ......\\n\\nRNN 순차처리\\nself-attention 병렬처리\\n\\n다중의미처리\\nriver bank  river를 강하게 참조\\nbank  loan  loan을 강하게 참조\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "the cat sat on the mat\n",
    "RNN 계열 : 왼쪽 -> 오른쪽 멀리떨어진 단어들은 서로 영향을 주고 받기 어려움\n",
    "\n",
    "The cat that the boy who lived here adopted is sleeping\n",
    "cat VS sleeping\n",
    "\n",
    "self-attention\n",
    "Q : 찾고 싶은 정보\n",
    "K : 가진 정보\n",
    "V : 최종 전달할 정보\n",
    "\n",
    "비교대상        유사도              의미\n",
    "cat vs the      낮음                the 의미없음\n",
    "cat vs cat      높음                자기자신\n",
    "cat vs sat      중간                동사와 연결\n",
    "cat vs on       낮음                on 전치사...\n",
    "cat vs mat      낮음                의미적으로 멀다\n",
    "\n",
    "softmax로 중요도 확률처럼 변경      유사도를 가중치로 변환\n",
    "단어            가중치\n",
    "the             0.05\n",
    "sat             0.3\n",
    "mat             0.05\n",
    "cat             0.6\n",
    "\n",
    "cat이 보는 시점은\n",
    "Query(cat) -> compare with -> Key(the) -> key(cat) -> key(sat)\n",
    "\n",
    "가중치\n",
    "the : 01  cat: 0.7   sat : 0.2\n",
    "출력 : 0.1*value(the) + ......\n",
    "\n",
    "RNN 순차처리\n",
    "self-attention 병렬처리\n",
    "\n",
    "다중의미처리\n",
    "river bank  river를 강하게 참조\n",
    "bank  loan  loan을 강하게 참조\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e10b41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAK7CAYAAAAZVPyBAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMitJREFUeJzt3Xu41XWd9//Xhs1xswFRREgFwa1ZicpomSjgKAN5yFHxkI1Kmtl9hwjarXkpAk6l4ngavbW7UlBTxDyNg45WKpamDh7wnI1HVMxDKuAJhf39/dHl/rUDFLbIhk+Px3Wt62qv7+n93broydfvWqumqqoqAABQiDatPQAAAKxKAhcAgKIIXAAAiiJwAQAoisAFAKAoAhcAgKIIXAAAiiJwAQAoisAFAKAoAhdoFffee2/23nvvbLzxxunQoUN69eqVr371qzn22GNbtL9Jkyalpqam2XMffPBBvvvd76Z3795p27Zttt5660/cz+uvv54OHTqkpqYm99133zLX+fGPf5zrr79+qecff/zxTJo0Kc8991wLzmDlLW+OWbNmpaamJrNmzVotc3xkzJgxqampyZ/+9Kdmz7/xxhtp06ZN2rVrl7fffrvZshdffDE1NTU55phjVupY/fr1y+jRo1s057Bhw/KlL33pE9ebN29eJk2alDlz5rToOEDrEbjAanfjjTdmhx12yIIFCzJlypT86le/yrnnnpvBgwdnxowZq+w4F154Yf7f//t/OfHEE3PnnXfmsssu+8RtLrvssnzwwQdJkosuumiZ63xc4E6ePLnVA3fQoEG5++67M2jQoNUyx0d23nnnJFkqrO+4447U1tampqYmd955Z7Nlt99+e7NtV9R1112XCRMmtHzYFTBv3rxMnjxZ4MJaqLa1BwD+/kyZMiWbbLJJbrnlltTW/v9/DB144IGZMmXKKjvOo48+mk6dOmXMmDErvM3FF1+c9ddfP3379s306dNz1llnpVOnTqtsptWha9eu2X777Vf7cYcNG9Z05fjAAw9sen7WrFnZbrvtUlVVbr/99owcObLZsjZt2mTIkCErdaxtttlmlc0NlMcVXGC1+/Of/5z11luvWdx+pE2bpf9YmjFjRr761a+mrq4uXbp0yYgRI/Lggw9+7DFqamry85//PO+9915qampSU1OTadOmfew29957bx599NEcfPDBOeKIIzJ//vxcc801S+33nXfeySWXXNK032HDhmXatGnZb7/9kvzlauSyjvmb3/wmu+yyS7p27ZrOnTtn8ODBufXWW5vt/6NbLR577LF84xvfSLdu3dKrV68cdthhmT9//ifOkSz/FoUbbrghX/3qV9O5c+fU19dn+PDhufvuu1t0/GVZd911s+WWWy513FmzZmXYsGEZOnRo0xXbv142aNCgdOvWLUmyYMGCfP/7388mm2yS9u3b53Of+1zGjRuXd955p9l2y7pF4bHHHss//dM/pXPnzunZs2e+973v5cYbb1zu7RqzZ8/OTjvtlM6dO6d///457bTT0tjY2DTXdtttlyT51re+1fQ7njRpUpLkmWeeyYEHHpg+ffo03WKzyy67uNoLawiBC6x2X/3qV3Pvvfdm7Nixuffee/Phhx8ud90f//jH+cY3vpEvfOELueqqq3LZZZdl4cKF2WmnnfL4448vd7u77747u+22Wzp16pS77747d999d3bfffePneujWxIOO+ywHHjggencufNStyncfffd6dSpU3bbbbem/V5wwQXZfffd8+Mf/zhJ8n//7/9d6pi/+MUv8k//9E/p2rVrLrnkklx11VXp0aNHRowYsVTkJsm+++6bzTbbLNdcc01+8IMf5Iorrsj48eM/cY7lueKKK7LXXnula9eumT59ei666KK8+eabGTZs2FK3DazI8Zdn5513zpNPPpmXX345yV/+MvPII49k6NChGTp0aB544IEsWLAgSfLCCy/kmWeeabo94d13383QoUNzySWXZOzYsfmv//qvHH/88Zk2bVq+/vWvp6qq5R735ZdfztChQ/Pkk0/mwgsvzKWXXpqFCxcu9+r9n/70p3zzm9/Mv/zLv+SGG27I1772tZxwwgn5xS9+keQvt3lMnTo1SXLSSSc1/Y6//e1vJ0l222233H///ZkyZUp+/etf58ILL8w222yTt9566xN/R8BqUAGsZq+//nq14447VkmqJFW7du2qHXbYoTr11FOrhQsXNq03d+7cqra2tjrqqKOabb9w4cJqgw02qPbff/+m5yZOnFj97R9phx56aFVXV7dCM73zzjtV165dq+23377Z9jU1NdVTTz3VbN26urrq0EMPXWofv/zlL6sk1e23377Uvnv06FHtueeezZ5fsmRJtdVWW1Vf/vKXlzqPKVOmNFv3f//v/1117Nixamxs/MQ5br/99mZzLFmypOrTp0+15ZZbVkuWLGlab+HChdX6669f7bDDDi06/rJcf/31VZLqiiuuqKqqqq655pqqtra2WrhwYbVgwYKqbdu21cyZM6uqqqpLLrmkSlLddNNNVVVV1amnnlq1adOmmj17drN9Xn311c3Wq6qq6tu3b7Nz/z//5/9UNTU11WOPPdZs2xEjRiz1z2To0KFVkuree+9ttu4XvvCFasSIEU0/z549u0pSTZ06tdl6r7/+epWkOueccz72dwG0HldwgdVu3XXXze9+97vMnj07p512Wvbaa6/88Y9/zAknnJAtt9wyr7/+epLklltuyeLFi3PIIYdk8eLFTY+OHTtm6NChK/0pAY2Njc32s2TJkqZlV111VRYsWJDDDjus6bnDDjssVVU1Xclrqd///vd54403cuihhzY7fmNjY0aOHJnZs2cv9Z/gv/71rzf7eeDAgXn//ffz6quvrvTxn3zyycybNy8HH3xws1tAunTpkn333Tf33HNP3n333VVy/KFDh6ZNmzZN/2xmzZqVbbfdNl26dEl9fX0GDRrUdJvCrFmzUltbmx133DFJMnPmzHzpS1/K1ltv3ez3NGLEiE/8VIg77rgjX/rSl/KFL3yh2fPf+MY3lrn+BhtskC9/+ctLnePzzz//seeXJD169MiAAQNyxhln5KyzzsqDDz7YdGsDsGYQuECr2XbbbXP88cfnl7/8ZebNm5fx48fnueeea3qj2SuvvJIk2W677dKuXbtmjxkzZjSF8Io65ZRTmu1jwIABTcsuuuiidOzYMSNHjsxbb72Vt956KwMHDky/fv0ybdq0ZjG8sj46j1GjRi11Hqeffnqqqsobb7zRbJt111232c8dOnRIkrz33nsrffw///nPSZLevXsvtaxPnz5pbGzMm2++uUqO371792y99dZNEXv77bdn6NChTcv/+i8mt99+e7bddtvU19cn+cvv6eGHH17qd1RfX5+qqj72n/ef//zn9OrVa6nnl/Xcss7vo3Nckd9vTU1Nbr311owYMSJTpkzJoEGD0rNnz4wdOzYLFy78xO2Bz55PUQDWCO3atcvEiRNz9tln59FHH02SrLfeekmSq6++On379v3Ux/jOd76TPfbYo+nnj6Ltj3/8Y9N9qBtvvPEyt73llluy2267tei4H53Heeedt9xPN1heiK0KH8XcR/fF/rV58+alTZs2WWeddVbZ8XbeeeeceeaZefjhh/PYY481+2SMoUOH5qyzzsrDDz+c5557rtkV1vXWWy+dOnXKxRdfvMz9fvR7XJZ111236S8Sf+1vP5N3Venbt2/T/dl//OMfc9VVV2XSpEn54IMP8pOf/OQzOSaw4gQusNq9/PLLy7ya+MQTTyT5y1XFJBkxYkRqa2vz9NNPZ9999/3Ux+3Tp0/Tvv/aR6Hys5/9LJtuummzZe+991722muvXHzxxU2Bu7wrfcu7yjl48OB07949jz/++Ep9ZNknWdErjptvvnk+97nP5Yorrsj3v//9pi/EeOedd3LNNdc0fbLCqvJR4E6ePDlt2rRpugUhSdP/njx5ctO6H9ljjz3y4x//OOuuu2422WSTlTrm0KFD82//9m95/PHHm92mcOWVV7b4PFb0qvVmm22Wk046Kddcc00eeOCBFh8PWHUELrDajRgxIhtuuGH23HPPfP7zn09jY2PmzJmTM888M126dMnRRx+d5C8fBXXKKafkxBNPzDPPPJORI0dmnXXWySuvvJL//u//Tl1dXVMotdTixYtz6aWXZosttmh6h/zf2nPPPXPDDTfktddeS8+ePZs+Cus///M/07t379TX12fzzTdv+nasn/70p6mvr0/Hjh2zySabZN111815552XQw89NG+88UZGjRqV9ddfP6+99loeeuihvPbaa7nwwgtXevblzfG32rRpkylTpuSb3/xm9thjjxx55JFZtGhRzjjjjLz11ls57bTTVvrYH2fIkCFp27Ztrrvuuma3ICR/uYVhq622ynXXXZd27dpl8ODBTcvGjRuXa665JkOGDMn48eMzcODANDY2Zu7cufnVr36VY489Nl/5yleWecxx48bl4osvzte+9rWccsop6dWrV6644or84Q9/aPodrKwBAwakU6dOufzyy7PFFlukS5cu6dOnT15//fWMGTMm++23XxoaGtK+ffvcdtttefjhh/ODH/xgpY8DfAZa+U1uwN+hGTNmVAcddFDV0NBQdenSpWrXrl218cYbVwcffHD1+OOPL7X+9ddfX+28885V165dqw4dOlR9+/atRo0aVf3mN79pWqeln6Lw0bv+P+4d8TfffHOVpDrzzDOrqqqqOXPmVIMHD646d+5cJamGDh3atO4555xTbbLJJlXbtm2Xegf+HXfcUe2+++5Vjx49qnbt2lWf+9znqt1337365S9/udR5vPbaa81mmDp1apWkevbZZ5ueW94cf/spCn99rl/5yleqjh07VnV1ddUuu+xS3XXXXc3WWZnjf5wvf/nLVZLq+9///lLLxo0bVyWpBg8evNSyt99+uzrppJOqzTffvGrfvn3VrVu3asstt6zGjx9f/elPf2pa728/RaGqqurRRx+tdt1116pjx45Vjx49qsMPP7zpkxoeeuihpvWGDh1affGLX1zq2IceemjVt2/fZs9Nnz69+vznP1+1a9euSlJNnDixeuWVV6rRo0dXn//856u6urqqS5cu1cCBA6uzzz67Wrx48Qr9foDPVk1VfcwHCwLAWuw73/lOpk+fnj//+c9p3759a48DrCZuUQCgCKecckr69OmT/v375+23387MmTPz85//PCeddJK4hb8zAheAIrRr1y5nnHFGXnzxxSxevDgNDQ0566yzmu7pBv5+uEUBAICi+KIHAACKInABACiKwAUAoCjeZLYMjY2NmTdvXurr65u+8QcAgNZTVVUWLlyYPn36fOKXtwjcZZg3b1422mij1h4DAIC/8cILL2TDDTf82HUE7jJ89LWS47NJOriLA1bID578TmuPAGuVmg2W/bXDwLItWPBONtpo92Zf/708AncZProtoUPapGPatvI0sHboWt+ptUeAtUpN1y6tPQKslVbk9lGXJwEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiFB+4kyZNytZbb93aYwAAsJoUH7gAAPx9WSsCt7GxMaeffno23XTTdOjQIRtvvHF+9KMfJUmOP/74bLbZZuncuXP69++fCRMm5MMPP0ySTJs2LZMnT85DDz2Umpqa1NTUZNq0aa14JgAAfNZqW3uAFXHCCSfkZz/7Wc4+++zsuOOOefnll/OHP/whSVJfX59p06alT58+eeSRR3LEEUekvr4+xx13XA444IA8+uijufnmm/Ob3/wmSdKtW7el9r9o0aIsWrSo6ecFCxasnhMDAGCVW+MDd+HChTn33HNz/vnn59BDD02SDBgwIDvuuGOS5KSTTmpat1+/fjn22GMzY8aMHHfccenUqVO6dOmS2trabLDBBss9xqmnnprJkyd/ticCAMBqscbfovDEE09k0aJF2WWXXZa5/Oqrr86OO+6YDTbYIF26dMmECRMyd+7clTrGCSeckPnz5zc9XnjhhVUxOgAArWCND9xOnTotd9k999yTAw88MF/72tcyc+bMPPjggznxxBPzwQcfrNQxOnTokK5duzZ7AACwdlrjA7ehoSGdOnXKrbfeutSyu+66K3379s2JJ56YbbfdNg0NDXn++eebrdO+ffssWbJkdY0LAEArW+Pvwe3YsWOOP/74HHfccWnfvn0GDx6c1157LY899lg23XTTzJ07N1deeWW222673Hjjjbnuuuuabd+vX788++yzmTNnTjbccMPU19enQ4cOrXQ2AAB81tb4K7hJMmHChBx77LE5+eSTs8UWW+SAAw7Iq6++mr322ivjx4/PmDFjsvXWW+f3v/99JkyY0GzbfffdNyNHjszOO++cnj17Zvr06a10FgAArA41VVVVrT3EmmbBggXp1q1bfpAB6Zi2rT0OrBVOnjemtUeAtUpN7x1aewRYqyxY8Ha6dRuW+fPnf+L7pdaKK7gAALCiBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQFIELAEBRBC4AAEURuAAAFEXgAgBQlNrWHmBN9oOZg9K1rl1rjwFrhXf2P6+1R4C1St1VrT0BrF2qhe+t8Lqu4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABRF4AIAUBSBCwBAUQQuAABFEbgAABSlRYE7adKkPP/886t6FgAA+NRaFLj/+Z//mQEDBmSXXXbJFVdckffff39VzwUAAC3SosC9//7788ADD2TgwIEZP358evfunf/1v/5XZs+evarnAwCAldLie3AHDhyYs88+Oy+99FIuvvjivPTSSxk8eHC23HLLnHvuuZk/f/6qnBMAAFbIp36TWWNjYz744IMsWrQoVVWlR48eufDCC7PRRhtlxowZq2JGAABYYS0O3Pvvvz9jxoxJ7969M378+GyzzTZ54okncscdd+QPf/hDJk6cmLFjx67KWQEA4BO1KHAHDhyY7bffPs8++2wuuuiivPDCCznttNOy6aabNq1zyCGH5LXXXltlgwIAwIqobclG++23Xw477LB87nOfW+46PXv2TGNjY4sHAwCAlljpK7gffvhhpk6d6k1kAACskVY6cNu1a5dFixalpqbms5gHAAA+lRbdg3vUUUfl9NNPz+LFi1f1PAAA8Km06B7ce++9N7feemt+9atfZcstt0xdXV2z5ddee+0qGQ4AAFZWiwK3e/fu2XfffVf1LAAA8Km1KHCnTp26qudopqqqHHnkkbn66qvz5ptvplu3bhk9enTOOeecT9x22LBh2XrrrVdoXQAAytOiwE2SxYsXZ9asWXn66adz0EEHpb6+PvPmzUvXrl3TpUuXTzXUzTffnGnTpmXWrFnp379/2rRpk06dOn2qfQIA8PehRYH7/PPPZ+TIkZk7d24WLVqU4cOHp76+PlOmTMn777+fn/zkJ59qqKeffjq9e/fODjvs8Kn2AwDA358WfYrC0UcfnW233TZvvvlmsyure++9d2699dZPNdDo0aNz1FFHZe7cuampqUm/fv0ybNiwjBs3rmmdCy64IA0NDenYsWN69eqVUaNGNdtHY2NjjjvuuPTo0SMbbLBBJk2a9KlmAgBg7dGiK7h33nln7rrrrrRv377Z83379s1LL730qQY699xzM2DAgPz0pz/N7Nmz07Zt2+y3335Ny++7776MHTs2l112WXbYYYe88cYb+d3vftdsH5dcckmOOeaY3Hvvvbn77rszevToDB48OMOHD1/mMRctWpRFixY1/bxgwYJPdQ4AALSeFgVuY2NjlixZstTzL774Yurr6z/VQN26dUt9fX3atm2bDTbYYKnlc+fOTV1dXfbYY4/U19enb9++2WabbZqtM3DgwEycODFJ0tDQkPPPPz+33nrrcgP31FNPzeTJkz/V3AAArBladIvC8OHDm31KQU1NTd5+++1MnDgxu+2226qabbnH7tu3b/r375+DDz44l19+ed59991m6wwcOLDZz717986rr7663H2ecMIJmT9/ftPjhRde+ExmBwDgs9eiwD377LNzxx135Atf+ELef//9HHTQQenXr19eeumlnH766at6xmbq6+vzwAMPZPr06endu3dOPvnkbLXVVnnrrbea1mnXrl2zbWpqatLY2LjcfXbo0CFdu3Zt9gAAYO3UolsU+vTpkzlz5mT69Ol54IEH0tjYmMMPPzzf/OY3V8vHedXW1mbXXXfNrrvumokTJ6Z79+657bbbss8++3zmxwYAYM3W4s/B7dSpUw477LAcdthhq3KeTzRz5sw888wzGTJkSNZZZ53cdNNNaWxszOabb75a5wAAYM3UosC99NJLP3b5IYcc0qJhVkT37t1z7bXXZtKkSXn//ffT0NCQ6dOn54tf/OJndkwAANYeNVVVVSu70TrrrNPs5w8//DDvvvtu2rdvn86dO+eNN95YZQO2hgULFqRbt255a+Z+6VrX7pM3APLOhNmtPQKsVequOqq1R4C1yoKF76X75sdn/vz5n/h+qRa9yezNN99s9nj77bfz5JNPZscdd8z06dNbNDQAAKwKLQrcZWloaMhpp52Wo48+elXtEgAAVtoqC9wkadu2bebNm7cqdwkAACulRW8yu+GGG5r9XFVVXn755Zx//vkZPHjwKhkMAABaokWB+8///M/Nfq6pqUnPnj3zj//4jznzzDNXxVwAANAiLQrcj/tWMAAAaE0tCtxjjjlmhdc966yzWnIIAABokRYF7oMPPpj7778/S5YsafoGsT/+8Y9p27ZtBg0a1LReTU3NqpkSAABWUIsCd88990x9fX0uueSSpi99ePPNN/Otb30rO+20U4499thVOiQAAKyoFn1M2JlnnplTTz212TearbPOOvnhD3/oTWYAALSqFgXuggUL8sorryz1/KuvvpqFCxd+6qEAAKClWhS4e++9d771rW/l6quvzosvvpgXX3wxV199dQ4//PDss88+q3pGAABYYS26B/cnP/lJvv/97+df/uVf8uGHH/5lR7W1Ofzww3PGGWes0gEBAGBltChwO3funAsuuCBnnHFGnn766VRVlU033TR1dXWrej4AAFgpLQrcj9TV1WXgwIGrahYAAPjUWnQPLgAArKkELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFCU2tYeYE3WOGduGjv6FcGKqPvX7Vp7BFi7PHlPa08Aa5d3PlzhVV3BBQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKAIXAICiCFwAAIoicAEAKIrABQCgKK0auMOGDcu4ceOSJP369cs555zTtKympibXX399q8wFAMDaq7a1B/jI7NmzU1dX19pjAACwlltjArdnz56tPQIAAAVYY+7B/dtbFP7WKaeckl69emXOnDlJkt///vcZMmRIOnXqlI022ihjx47NO++807T+BRdckIaGhnTs2DG9evXKqFGjPuMzAABgTbDGBO7yVFWVo48+OhdddFHuvPPObL311nnkkUcyYsSI7LPPPnn44YczY8aM3HnnnRkzZkyS5L777svYsWNzyimn5Mknn8zNN9+cIUOGLPcYixYtyoIFC5o9AABYO60xtygsy+LFi3PIIYfkvvvuy1133ZUNN9wwSXLGGWfkoIMOanqDWkNDQ/793/89Q4cOzYUXXpi5c+emrq4ue+yxR+rr69O3b99ss802yz3OqaeemsmTJ6+OUwIA4DO2Rgfu+PHj06FDh9xzzz1Zb731mp6///7789RTT+Xyyy9veq6qqjQ2NubZZ5/N8OHD07dv3/Tv3z8jR47MyJEjs/fee6dz587LPM4JJ5yQY445punnBQsWZKONNvrsTgwAgM/MGn2LwvDhw/PSSy/llltuafZ8Y2NjjjzyyMyZM6fp8dBDD+V//ud/MmDAgNTX1+eBBx7I9OnT07t375x88snZaqut8tZbby3zOB06dEjXrl2bPQAAWDut0Vdwv/71r2fPPffMQQcdlLZt2+bAAw9MkgwaNCiPPfZYNt100+VuW1tbm1133TW77rprJk6cmO7du+e2227LPvvss7rGBwCgFazRgZske++9dy677LIcfPDBqa2tzahRo3L88cdn++23z/e+970cccQRqauryxNPPJFf//rXOe+88zJz5sw888wzGTJkSNZZZ53cdNNNaWxszOabb97apwMAwGdsjQ/cJBk1alQaGxtz8MEHp02bNtlnn31yxx135MQTT8xOO+2UqqoyYMCAHHDAAUmS7t2759prr82kSZPy/vvvp6GhIdOnT88Xv/jFVj4TAAA+azVVVVWtPcSaZsGCBenWrVve+OFX0rXjWvF3AGh1bf6hb2uPAEDBFrzzYbrv8cvMnz//E98vtUa/yQwAAFaWwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAoghcAACKInABACiKwAUAoCgCFwCAotS29gBroqqqkiQL3l/cypPA2qPNOx+29ggAFGzBu3/5/5mPOu3j1FQrstbfmRdffDEbbbRRa48BAMDfeOGFF7Lhhht+7DoCdxkaGxszb9681NfXp6amprXH4a8sWLAgG220UV544YV07dq1tceBNZ7XDKw8r5s1U1VVWbhwYfr06ZM2bT7+Llu3KCxDmzZtPvFvBrSurl27+kMHVoLXDKw8r5s1T7du3VZoPW8yAwCgKAIXAICiCFzWKh06dMjEiRPToUOH1h4F1gpeM7DyvG7Wft5kBgBAUVzBBQCgKAIXAICiCFwAAIoicAHWQlVV5Tvf+U569OiRmpqadO/ePePGjVuhbYcNG7bC68La7K//Xe/Xr1/OOeecpmU1NTW5/vrrW2UuPnu+6IFiTJo0Kddff33mzJnT2qPAZ+7mm2/OtGnTMmvWrPTv3z9t2rRJp06dWnssWGPNnj07dXV1rT0Gq4nABVgLPf300+ndu3d22GGH1h4F1go9e/Zs7RFYjdyiwBqlsbExp59+ejbddNN06NAhG2+8cX70ox8lSY4//vhsttlm6dy5c/r3758JEybkww8/TJJMmzYtkydPzkMPPZSamprU1NRk2rRprXgm8NkZPXp0jjrqqMydOzc1NTXp16/fUrcdXHDBBWloaEjHjh3Tq1evjBo1qtk+Ghsbc9xxx6VHjx7ZYIMNMmnSpNV7ErCa/e0tCn/rlFNOSa9evZr+K+Dvf//7DBkyJJ06dcpGG22UsWPH5p133mla/5NeY7QuV3BZo5xwwgn52c9+lrPPPjs77rhjXn755fzhD39IktTX12fatGnp06dPHnnkkRxxxBGpr6/PcccdlwMOOCCPPvpobr755vzmN79JsuLfVw1rm3PPPTcDBgzIT3/608yePTtt27bNfvvt17T8vvvuy9ixY3PZZZdlhx12yBtvvJHf/e53zfZxySWX5Jhjjsm9996bu+++O6NHj87gwYMzfPjw1X060Kqqqsq4ceNy/fXX584770xDQ0MeeeSRjBgxIv/6r/+aiy66KK+99lrGjBmTMWPGZOrUqSv0GqN1CVzWGAsXLsy5556b888/P4ceemiSZMCAAdlxxx2TJCeddFLTuv369cuxxx6bGTNm5LjjjkunTp3SpUuX1NbWZoMNNmiV+WF16datW+rr69O2bdtl/vs+d+7c1NXVZY899kh9fX369u2bbbbZptk6AwcOzMSJE5MkDQ0NOf/883PrrbcKXP6uLF68OIccckjuu+++3HXXXdlwww2TJGeccUYOOuigpv8q0tDQkH//93/P0KFDc+GFF67Qa4zWJXBZYzzxxBNZtGhRdtlll2Uuv/rqq3POOefkqaeeyttvv53Fixena9euq3lKWPMNHz48ffv2Tf/+/TNy5MiMHDkye++9dzp37ty0zsCBA5tt07t377z66qure1RoVePHj0+HDh1yzz33ZL311mt6/v77789TTz2Vyy+/vOm5qqrS2NiYZ599doVeY7Qu9+Cyxvi4d4Dfc889OfDAA/O1r30tM2fOzIMPPpgTTzwxH3zwwWqcENYO9fX1eeCBBzJ9+vT07t07J598crbaaqu89dZbTeu0a9eu2TY1NTVpbGxczZNC6xo+fHheeuml3HLLLc2eb2xszJFHHpk5c+Y0PR566KH8z//8TwYMGLBCrzFal8BljdHQ0JBOnTrl1ltvXWrZXXfdlb59++bEE0/Mtttum4aGhjz//PPN1mnfvn2WLFmyusaFNVptbW123XXXTJkyJQ8//HCee+653Hbbba09FqxRvv71r+eKK67It7/97Vx55ZVNzw8aNCiPPfZYNt1006Ue7du3T+I1tqZziwJrjI4dO+b444/Pcccdl/bt22fw4MF57bXXmv6QmTt3bq688spst912ufHGG3Pdddc1275fv3559tlnM2fOnGy44Yapr69Phw4dWulsoPXMnDkzzzzzTIYMGZJ11lknN910UxobG7P55pu39miwxtl7771z2WWX5eCDD05tbW1GjRqV448/Pttvv32+973v5YgjjkhdXV2eeOKJ/PrXv855553nNbYWELisUSZMmJDa2tqcfPLJmTdvXnr37p3vfve7OfzwwzN+/PiMGTMmixYtyu67754JEyY0+2ijfffdN9dee2123nnnvPXWW5k6dWpGjx7daucCraV79+659tprM2nSpLz//vtpaGjI9OnT88UvfrG1R4M10qhRo9LY2JiDDz44bdq0yT777JM77rgjJ554YnbaaadUVZUBAwbkgAMOSOI1tjaoqaqqau0hAABgVXEPLgAARRG4AAAUReACAFAUgQsAQFEELgAARRG4AAAUReACAFAUgQsAQFEELsBaaNiwYRk3blxrjwGwRhK4AAAUReACAFAUgQtQgJtvvjndunXLpZdempdeeikHHHBA1llnnay77rrZa6+98txzzyVJfvvb36Zdu3b505/+1Gz7Y489NkOGDGmFyQFWPYELsJa78sors//+++fSSy/NqFGjsvPOO6dLly757W9/mzvvvDNdunTJyJEj88EHH2TIkCHp379/LrvssqbtFy9enF/84hf51re+1YpnAbDqCFyAtdgFF1yQ7373u/mP//iP7LXXXrnyyivTpk2b/PznP8+WW26ZLbbYIlOnTs3cuXMza9asJMnhhx+eqVOnNu3jxhtvzLvvvpv999+/lc4CYNWqbe0BAGiZa665Jq+88kruvPPOfPnLX06S3H///XnqqadSX1/fbN33338/Tz/9dJJk9OjROemkk3LPPfdk++23z8UXX5z9998/dXV1q/0cAD4LAhdgLbX11lvngQceyNSpU7PddtulpqYmjY2N+Yd/+IdcfvnlS63fs2fPJMn666+fPffcM1OnTk3//v1z0003NV3dBSiBwAVYSw0YMCBnnnlmhg0blrZt2+b888/PoEGDMmPGjKy//vrp2rXrcrf99re/nQMPPDAbbrhhBgwYkMGDB6/GyQE+W+7BBViLbbbZZrn99ttzzTXXZNy4cfnmN7+Z9dZbL3vttVd+97vf5dlnn80dd9yRo48+Oi+++GLTdiNGjEi3bt3ywx/+0JvLgOIIXIC13Oabb57bbrst06dPz4QJE/Lb3/42G2+8cfbZZ59sscUWOeyww/Lee+81u6Lbpk2bjB49OkuWLMkhhxzSitMDrHo1VVVVrT0EAKvfEUcckVdeeSU33HBDa48CsEq5Bxfg78z8+fMze/bsXH755fmP//iP1h4HYJUTuAB/Z/baa6/893//d4488sgMHz68tccBWOXcogAAQFG8yQwAgKIIXAAAiiJwAQAoisAFAKAoAhcAgKIIXAAAiiJwAQAoisAFAKAo/x+8rj2cMu9MZgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# self-attention 시각화\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "words = ['cat', 'fish', 'likes'] # 고양이가 생선을 좋아한다.\n",
    "# 가상의 attention 가중치\n",
    "# 각 행은 해당 단어가 다른단어들에게 주목하는 정도\n",
    "attention_weights = np.array([\n",
    "    [0.7, 0.2, 0.1],    #고양이는 자기 자신에게 가장 높은 가중치\n",
    "    [0.3, 0.5, 0.2],    #생선에 대해 가장 높은 가중치\n",
    "    [0.4, 0.3, 0.3]     #좋아한다에 대해 가장 높은 가중치\n",
    "])\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(attention_weights, cmap='YlOrRd')\n",
    "ax.set_xticks(range(len(words)))\n",
    "ax.set_yticks(range(len(words)))\n",
    "ax.set_xticklabels(words)\n",
    "ax.set_yticklabels(words)\n",
    "ax.set_xlabel('key')\n",
    "ax.set_ylabel('query')\n",
    "ax.set_title('Self-Attention Weights')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ffb0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beam Search\n",
    "# 문장을 생성할 때 다음에 나올단어는 수천~수만개가 될 수 있는데, 이걸 경우의 수로 따지면.... X\n",
    "# 상위 N개의 후보만 유지, N을 beam size라고 함\n",
    "# beam size = 1 매번 가장 좋은 것만 선택(Greedy)\n",
    "# beam size = 4 4개의 가능성을 동시에 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "557e650f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 : summarize: The Amazon rainforest is the world's largest tropical rainforest. \n",
      "    It covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries. \n",
      "    The Amazon is home to millions of species of plants and animals, many of which are found nowhere else on Earth. \n",
      "    However, deforestation poses a significant threat to this vital ecosystem.\n",
      ": The Amazon rainforest is the world's largest tropical rainforest. \n",
      "    It covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries. \n",
      "    The Amazon is home to millions of species of plants and animals, many of which are found nowhere else on Earth. \n",
      "    However, deforestation poses a significant threat to this vital ecosystem.\n",
      "beam size : 1\n",
      "요약 : the amazon rainforest covers much of northwestern Brazil. it extends into Colombia, Peru and other South american countries.\n",
      "beam size : 2\n",
      "요약 : the amazon rainforest covers much of northwestern Brazil. it extends into Colombia, Peru and other south american countries.\n",
      "beam size : 4\n",
      "요약 : the amazon rainforest covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries. deforestation poses a significant threat to this vital ecosystem.\n",
      "beam size : 8\n",
      "요약 : the amazon rainforest covers much of northwestern Brazil. it extends into Colombia, Peru and other south american countries.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer # Hugging Face Transformers 라이브러리에서 시퀀스-투-시퀀스 모델과 토크나이저를 로드하기 위한 클래스\n",
    "import torch # PyTorch 딥러닝 프레임워크, GPU 가속 및 텐서 연산을 위해 사용\n",
    "import time # 시간 관련 함수를 제공하는 표준 라이브러리, 주로 코드 실행 시간 측정에 사용\n",
    "\n",
    "MODEL_NAME = \"t5-small\" # 사용할 T5 모델의 이름을 정의합니다. 여기서는 't5-small' 버전을 사용합니다.\n",
    "\n",
    "# AutoTokenizer.from_pretrained()를 사용하여 사전 훈련된 모델에 맞는 토크나이저를 로드합니다.\n",
    "# 토크나이저는 텍스트를 모델이 이해할 수 있는 숫자 ID 시퀀스로 변환하는 역할을 합니다.\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# AutoModelForSeq2SeqLM.from_pretrained()를 사용하여 사전 훈련된 시퀀스-투-시퀀스 모델을 로드합니다.\n",
    "# 이 모델은 텍스트 요약, 번역 등 시퀀스-투-시퀀스 태스크에 사용됩니다.\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# PyTorch를 사용하여 모델을 실행할 장치(device)를 설정합니다.\n",
    "# CUDA(GPU)가 사용 가능하면 GPU를 사용하고, 그렇지 않으면 CPU를 사용합니다.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# 모델을 선택된 장치로 이동시켜 해당 장치에서 연산이 수행되도록 합니다.\n",
    "model = model.to(device)\n",
    "\n",
    "text = \"\"\"summarize: The Amazon rainforest is the world's largest tropical rainforest. \n",
    "    It covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries. \n",
    "    The Amazon is home to millions of species of plants and animals, many of which are found nowhere else on Earth. \n",
    "    However, deforestation poses a significant threat to this vital ecosystem.\"\"\"\n",
    "\n",
    "print(f'원본 : {text}')\n",
    "print(text.replace(\"summarize\",\"\"))\n",
    "# 입력 텍스트를 토크나이저를 통해 모델 입력 형식으로 변환합니다.\n",
    "# 'return_tensors=\"pt\"'는 PyTorch 텐서로 반환하도록 지정합니다.\n",
    "# 'max_length=512'는 입력 시퀀스의 최대 길이를 512로 제한합니다.\n",
    "# 'truncation=True'는 최대 길이를 초과하는 경우 텍스트를 자르도록 합니다.\n",
    "# '.to(device)'는 생성된 텐서를 모델이 있는 장치(CPU 또는 GPU)로 이동시킵니다.\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "\n",
    "# 다양한 빔 크기(num_beams)를 실험하기 위한 리스트를 정의합니다.\n",
    "beam_size = [1,2,4,8] # 빔 서치(beam search) 디코딩 전략에서 사용할 빔의 개수들을 정의한 리스트입니다. 각 숫자는 요약 생성 시 고려할 후보 시퀀스의 수를 나타냅니다.\n",
    "# 각 빔 크기에서의 결과(빔 크기, 요약 텍스트, 소요 시간)를 저장할 리스트를 초기화합니다.\n",
    "results = []\n",
    "# 정의된 각 빔 크기에 대해 반복합니다.\n",
    "for num_beams in beam_size:\n",
    "    # 현재 실험 중인 빔 크기를 출력합니다.\n",
    "    print(f'beam size : {num_beams}')\n",
    "    # 현재 빔 크기에서의 요약 생성 시작 시간을 기록합니다.\n",
    "    start_time = time.time()\n",
    "    # 모델의 'generate' 메서드를 사용하여 요약을 생성합니다.\n",
    "    outputs= model.generate(\n",
    "        # 'inputs'는 토크나이징된 입력 텍스트를 전달합니다.\n",
    "        **inputs,\n",
    "        # 현재 반복의 빔 크기를 설정합니다.\n",
    "        num_beams=num_beams,\n",
    "        # 생성될 요약문의 최대 길이를 60으로 제한합니다.\n",
    "        max_length=60,\n",
    "        # 생성될 요약문의 최소 길이를 20으로 설정합니다.\n",
    "        min_length=20,\n",
    "        # 'early_stopping=True'는 모든 빔이 EOS(문장 끝) 토큰에 도달하거나 최대 길이에 도달하면 생성을 중지합니다.\n",
    "        early_stopping=True,\n",
    "        # 'no_repeat_ngram_size=3'은 3-gram이 반복되지 않도록 하여 텍스트의 자연스러움을 높입니다.\n",
    "        no_repeat_ngram_size=3,\n",
    "        # 생성할 시퀀스의 수를 1로 설정합니다 (가장 좋은 하나의 요약).\n",
    "        num_return_sequences=1\n",
    "        )\n",
    "    # 요약 생성에 걸린 시간을 계산합니다.\n",
    "    elapsed_time = time.time() - start_time\n",
    "    # 생성된 토큰 ID 시퀀스를 사람이 읽을 수 있는 텍스트로 디코딩합니다.\n",
    "    # 'skip_special_tokens=True'는 EOS, BOS 같은 특수 토큰을 결과에서 제외합니다.\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # 현재 빔 크기, 생성된 요약, 소요 시간을 결과 리스트에 추가합니다.\n",
    "    results.append((num_beams, summary, elapsed_time))\n",
    "    print(f'요약 : {summary}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b59024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam size : 1\n",
      "측정 시간 : 0.4722015857696533초\n",
      "요약 : the amazon rainforest covers much of northwestern Brazil. it extends into Colombia, Peru and other South american countries.\n",
      "beam size : 2\n",
      "측정 시간 : 0.4067976474761963초\n",
      "요약 : the amazon rainforest covers much of northwestern Brazil. it extends into Colombia, Peru and other south american countries.\n",
      "beam size : 4\n",
      "측정 시간 : 0.5565969944000244초\n",
      "요약 : the amazon rainforest covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries. deforestation poses a significant threat to this vital ecosystem.\n",
      "beam size : 8\n",
      "측정 시간 : 0.5874490737915039초\n",
      "요약 : the amazon rainforest covers much of northwestern Brazil. it extends into Colombia, Peru and other south american countries.\n"
     ]
    }
   ],
   "source": [
    "for num_beams, summary, elapsed_time in results:\n",
    "    print(f'beam size : {num_beams}')\n",
    "    print(f'측정 시간 : {elapsed_time}초')\n",
    "    print(f'요약 : {summary}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b82fb75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nROUGE 매트릭\\n문서를 요약했는데 어떻게 품질을 측정\\n겹침 정도를 측정\\nROGUE-1 단어단위\\n    정답: 고양이가 생선을 먹었다.\\n    생성: 고양이가 물고기를 먹었다\\n    겹침: 고양이가 먹었다 2/4 0.5\\nROGUE-2 2개 단위 : 순서도 고려\\nROGUE-L 가장 긴 공통 부분수열(순서는 유지하지만 연속적이지 않아도 됨.)\\n\\n    단점: 의미는 같지만 다른표현을 쓰면 점수가 낮다.\\n        자동차 VS 차량 겹침 없음으로 판단.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ROUGE 매트릭\n",
    "문서를 요약했는데 어떻게 품질을 측정\n",
    "겹침 정도를 측정\n",
    "ROGUE-1 단어단위\n",
    "    정답: 고양이가 생선을 먹었다.\n",
    "    생성: 고양이가 물고기를 먹었다\n",
    "    겹침: 고양이가 먹었다 2/4 0.5\n",
    "ROGUE-2 2개 단위 : 순서도 고려\n",
    "ROGUE-L 가장 긴 공통 부분수열(순서는 유지하지만 연속적이지 않아도 됨.)\n",
    "\n",
    "    단점: 의미는 같지만 다른표현을 쓰면 점수가 낮다.\n",
    "        자동차 VS 차량 겹침 없음으로 판단.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cde6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이져"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0560a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간 : 0.9255599975585938\n",
      "문장당:, 0.1157\n"
     ]
    }
   ],
   "source": [
    "# 배치처리, 데이터 콜레이터(배치를 만들 때 길이를 맞춰주는 작업)\n",
    "# 효율적인 데이터 처리방법\n",
    "\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM\n",
    "import torch, time\n",
    "# AutoModelForSeq2SeqLM: 입력을 받아서 다른 텍스트 생성하는 Seq2Seq 모델을 위한 자동로드\n",
    "# Encoder-Decoder 모델을 자동으로\n",
    "# T5, BART, MarianMT\n",
    "# 번역/요약/QA/문장변환 입력->출력\n",
    "\n",
    "# DataCollatorForSeq2Seq: 배치를 만들 때 길이를 맞춰주는 작업\n",
    "# seq2seq 학습시 배치단위로 패딩-정렬-라벨 시프트 등을 자동처리하는 데이터 정렬 도구\n",
    "# 배치생성 - 길이가 다른 문장들을 동일길이로 패딩\n",
    "# 라벨 시프트 -라벨을 디코더 입력으로 사용 (teacher forcing에 필요한 작업)\n",
    "# DataLoader 안에서 사용\n",
    "MODEL_NAME = \"t5-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device) \n",
    "model.eval()\n",
    "\n",
    "texts = [\n",
    "    \"summarize: The cat sat on the mat.\",\n",
    "    \"summarize: Python is a popular programming language.\",\n",
    "    \"summarize: Machine learning is a subset of artificial intelligence.\",\n",
    "    \"summarize: The weather is nice today.\",\n",
    "    \"summarize: I love reading books in my free time.\",\n",
    "    \"summarize: Coffee is one of the most popular beverages worldwide.\",\n",
    "    \"summarize: Regular exercise is important for health.\",\n",
    "    \"summarize: The Internet has changed how we communicate.\",\n",
    "]\n",
    "# 개별처리 VS 배치처리\n",
    "start_time = time.time()\n",
    "result_indivisual = []\n",
    "with torch.no_grad():\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "        outputs = model.generate(**inputs, max_length=30)\n",
    "        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            \n",
    "        result_indivisual.append(summary)\n",
    "time_individual = time.time() - start_time\n",
    "print(f\"소요시간 : {time_individual}\")\n",
    "print(f\"문장당:, {time_individual/len(texts):.4f}\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edda90d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요시간 : 0.16839075088500977\n",
      "문장당:, 0.0210\n"
     ]
    }
   ],
   "source": [
    "# 배치처리\n",
    "start_time = time.time()\n",
    "result_batch = []\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_length=30)\n",
    "    for output in outputs:\n",
    "        summary = tokenizer.decode(output, skip_special_tokens=True)\n",
    "        result_batch.append(summary)\n",
    "time_indivisual = time.time() - start_time\n",
    "print(f\"소요시간 : {time_indivisual}\")\n",
    "print(f\"문장당:, {time_indivisual/len(texts):.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96325a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[21603,    10,    37,  1712,     3,     7,   144,    30,     8,  6928,\n",
      "             5,     1,     0,     0],\n",
      "        [21603,    10, 20737,    19,     3,     9,  1012,  6020,  1612,     5,\n",
      "             1,     0,     0,     0],\n",
      "        [21603,    10,  5879,  1036,    19,     3,     9,   769,  2244,    13,\n",
      "          7353,  6123,     5,     1],\n",
      "        [21603,    10,    37,  1969,    19,  1245,   469,     5,     1,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [21603,    10,    27,   333,  1183,  1335,    16,    82,   339,    97,\n",
      "             5,     1,     0,     0],\n",
      "        [21603,    10, 10429,    19,    80,    13,     8,   167,  1012, 18928,\n",
      "          4388,     5,     1,     0],\n",
      "        [21603,    10, 17116,  2510,    19,   359,    21,   533,     5,     1,\n",
      "             0,     0,     0,     0],\n",
      "        [21603,    10,    37,  1284,    65,  2130,   149,    62,  4521,     5,\n",
      "             1,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "# 데이터콜레이터\n",
    "start_time = time.time()\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True)\n",
    "tokenized =[]\n",
    "for text in texts:\n",
    "    encoded = tokenizer(text, truncation=True)\n",
    "    tokenized.append(encoded)\n",
    "\n",
    "batch = data_collator(tokenized)\n",
    "print(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
