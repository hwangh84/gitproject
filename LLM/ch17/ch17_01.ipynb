{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9gQ3gP62ZcW"
      },
      "source": [
        "KoBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G2dIQFDy5LRS"
      },
      "outputs": [],
      "source": [
        "# !pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q4z73QTC3s3-"
      },
      "outputs": [],
      "source": [
        "# %pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MrRItwWK4vyb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
            "The class this function is called from is 'KoBERTTokenizer'.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2, 4958, 6855, 2046, 7088, 1050, 7843, 54, 3]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
        "tokenizer.encode(\"한국어 모델을 공유합니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fHcNdKPf6YoM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [2, 4958, 6855, 2046, 7088, 1050, 7843, 54, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer('한국어 모델을 공유합니다.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tVRLYpSS2ba_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertModel\n",
        "model = BertModel.from_pretrained('skt/kobert-base-v1')\n",
        "text = \"한국어 모델을 공유합니다.\"\n",
        "inputs = tokenizer.batch_encode_plus([text])\n",
        "out = model(input_ids = torch.tensor(inputs['input_ids']),\n",
        "              attention_mask = torch.tensor(inputs['attention_mask']))\n",
        "out.pooler_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WuuCKmL66_6B"
      },
      "outputs": [],
      "source": [
        "# 데이터셋클래스\n",
        "import torch\n",
        "class OurDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings, labels):\n",
        "    self.encodings = encodings\n",
        "    self.labels = labels\n",
        "  def __getitem__(self, idx):\n",
        "    item = {key: torch.tensor(val[idx].clone().detach()) for key, val in self.encodings.items()}\n",
        "    item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "    return item\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eGt5Er_I-VHZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14725\n",
            "1472\n"
          ]
        }
      ],
      "source": [
        "# 데이터 로드 및 분할(여기서는 성능상 일부 데이터만 사용)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# 데이터셋 로드\n",
        "url = \"https://drive.google.com/uc?id=1KOKgZ4qCg49bgj1QNTwk1Vd29soeB27o\"\n",
        "df = pd.read_csv(url)\n",
        "print(len(df))\n",
        "df = df.sample(frac=0.1)\n",
        "print(len(df))\n",
        "X = df.review.tolist()\n",
        "y = (df.rating >= 6).values.astype(int)\n",
        "x_,x_test,y_,y_test = train_test_split(X,y,stratify=y,random_state=42,test_size=0.2)\n",
        "x_train,x_val,y_train,y_val = train_test_split(x_,y_,stratify=y_, random_state=42,test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OxrAllZS8rM_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "c:\\Users\\khh11\\miniconda3\\envs\\pyt_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "C:\\Users\\khh11\\AppData\\Local\\Temp\\ipykernel_23312\\3125764579.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx].clone().detach()) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 1  train loss : 0.579280921842082\n",
            "val_loss : 0.5167392055193584\n",
            "epoch : 2  train loss : 0.4823796029313136\n",
            "val_loss : 0.5751420348882675\n",
            "epoch : 3  train loss : 0.42978419338242485\n",
            "val_loss : 0.5751420348882675\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# 토큰화\n",
        "train_input = tokenizer(x_train, truncation=True, padding=True,return_tensors='pt')\n",
        "val_input = tokenizer(x_val, truncation=True, padding=True, max_length=512,return_tensors='pt')\n",
        "test_input = tokenizer(x_test, truncation=True, padding=True, max_length=512,return_tensors='pt')\n",
        "# DataSet 생성\n",
        "train_dataset = OurDataset(train_input,y_train)\n",
        "val_dataset = OurDataset(val_input,y_val)\n",
        "test_dataset = OurDataset(test_input,y_test)\n",
        "# 데이터로더 생성\n",
        "train_loader = DataLoader(train_dataset, batch_size=8)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "# KoBERT 한국어 전용 모델 로드\n",
        "from transformers import BertModel\n",
        "model = BertModel.from_pretrained('skt/kobert-base-v1')\n",
        "# BERT를 포함한 신경망 모델\n",
        "import torch.nn as nn\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self,prefrained_model, token_size, num_labels):\n",
        "    super(MyModel,self).__init__()\n",
        "    self.prefrained_model=prefrained_model\n",
        "    self.token_size=token_size\n",
        "    self.num_labels=num_labels\n",
        "    # 분류기 정의\n",
        "    self.clf = nn.Linear(self.token_size,self.num_labels)\n",
        "  def forward(self,inputs):\n",
        "    outputs = self.prefrained_model(**inputs)  # [batch,embeding_dim,num_labels]\n",
        "    bert_clf_token = outputs.last_hidden_state[:,0,:]\n",
        "\n",
        "    return self.clf(bert_clf_token)\n",
        "model = MyModel(model,token_size = model.config.hidden_size,num_labels=2)\n",
        "# 학습 - 미니배치\n",
        "  # device\n",
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available()  else 'cpu'\n",
        "model.to(device)\n",
        "  # optimize\n",
        "# AdamW import\n",
        "from torch.optim import AdamW\n",
        "# from torch. import AdamW\n",
        "optim = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "  # 학습 스케줄러\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer=optim,\n",
        "                                            num_training_steps = len(train_loader),\n",
        "                                            num_warmup_steps=200)\n",
        "  # epoch수만큼 loop\n",
        "for epoch in range(3):\n",
        "  import numpy as np\n",
        "  total_loss = 0\n",
        "  for batch in train_loader:\n",
        "    model.train()\n",
        "    optim.zero_grad()\n",
        "    # 배치에서는 label을 제외하고 입력만 추출\n",
        "    inputs = {k : v.to(device) for k,v in batch.items() if k != 'labels'}\n",
        "    labels = batch['labels'].to(device)\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    scheduler.step()\n",
        "    total_loss += loss.item()\n",
        "  print(f'epoch : {epoch+1}  train loss : {total_loss / len(train_loader)}')\n",
        "  # val데이터로 해당 epoch 학습된 모델을 평가\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    for batch in val_loader:\n",
        "      inputs = {k : v.to(device) for k,v in batch.items() if k != 'labels'}\n",
        "      labels = batch['labels'].to(device)\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      total_val_loss += loss.item()\n",
        "    print(f'val_loss : {total_val_loss / len(val_loader)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\khh11\\AppData\\Local\\Temp\\ipykernel_23312\\3125764579.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx].clone().detach()) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.7559322033898305}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 평가\n",
        "import evaluate\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for batch in test_loader:\n",
        "    inputs = {k : v.to(device) for k,v in batch.items() if k != 'labels'}\n",
        "    labels = batch['labels'].to(device)\n",
        "    outputs = model(inputs)\n",
        "    predictions = torch.argmax(outputs, dim=-1)\n",
        "    metric.add_batch(predictions=predictions, references=labels)\n",
        "metric.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['나름 괜찮음',\n",
              " '최고 완성도에 가깝지만 마지막 라스트씬 공항 화장실 장면 넘 빨리끝났고 밋밋한게   아쉽다 ㅡㅡㅡ 강추',\n",
              " '통쾌합니다 범죄의도시  2  나올꺼죠??',\n",
              " '재밌게 봤어요. 형사들이 얼마나 힘들게 일하는지 목숨걸고 범죄자를 잡는지 느꼈어요. 그런데 너무 잔인해서 점수를 좀 깍고 싶은 마음.. 잔인하고 끔찍한 장면이 많아 수도 없이 눈과 귀를 가려야 했습니다.',\n",
              " '배우가 다 아는 배우. 도둑들 배우들은 암살에도 나오고 신과함께도 나오고. 그 배우가 그 배우. 뉴페이스는 없나봐요.']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = df.reset_index(drop=True)\n",
        "df2[-5:].review.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['나름 괜찮음',\n",
              " '최고 완성도에 가깝지만 마지막 라스트씬 공항 화장실 장면 넘 빨리끝났고 밋밋한게   아쉽다 ㅡㅡㅡ 강추',\n",
              " '통쾌합니다 범죄의도시  2  나올꺼죠??',\n",
              " '재밌게 봤어요. 형사들이 얼마나 힘들게 일하는지 목숨걸고 범죄자를 잡는지 느꼈어요. 그런데 너무 잔인해서 점수를 좀 깍고 싶은 마음.. 잔인하고 끔찍한 장면이 많아 수도 없이 눈과 귀를 가려야 했습니다.',\n",
              " '배우가 다 아는 배우. 도둑들 배우들은 암살에도 나오고 신과함께도 나오고. 그 배우가 그 배우. 뉴페이스는 없나봐요.']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2[-5:].review.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1], device='cuda:0')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "inputs = tokenizer(df2[-5:].review.values.tolist(),padding=True,truncation=True,return_tensors='pt',max_length=512)\n",
        "inputs = {k : v.to(device) for k,v in inputs.items()}\n",
        "outputs = model(inputs)\n",
        "preds = torch.softmax(outputs,dim = -1)\n",
        "preds = torch.argmax(preds,dim=-1)\n",
        "preds"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pyt_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
