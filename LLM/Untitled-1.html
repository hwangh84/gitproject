<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ëª¨ë¸ í•™ìŠµ ê²°ê³¼ì„œ</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; margin: 20px; }
        h1, h2, h3 { color: #333; }
        h1 { border-bottom: 3px solid #0056b3; padding-bottom: 10px; }
        h2 { border-bottom: 2px solid #ccc; padding-bottom: 5px; margin-top: 30px; }
        table { width: 100%; border-collapse: collapse; margin: 15px 0; }
        th, td { border: 1px solid #ddd; padding: 10px; text-align: left; }
        th { background-color: #f2f2f2; }
        pre { background-color: #eee; padding: 15px; border-radius: 5px; overflow-x: auto; }
        .highlight { background-color: #ffffe0; padding: 10px; border: 1px solid #ffcc00; }
    </style>
</head>
<body>

    <h1>ğŸ¤– ëª¨ë¸ í•™ìŠµ ê²°ê³¼ì„œ</h1>

    <p><strong>í”„ë¡œì íŠ¸ëª…</strong>: í•™ìƒ í•™ì—… ì¤‘ë„ ì´íƒˆë¥  ì˜ˆì¸¡<br>
    <strong>ì‘ì„±ì¼</strong>: 2025ë…„ 11ì›” 4ì¼<br>
    <strong>ë‹´ë‹¹</strong>: Drop Signal Detector Team</p>

    <hr>

    <h2>1. ëª¨ë¸ë§ ê°œìš”</h2>

    <h3>1.1 ë¬¸ì œ ì •ì˜</h3>
    <ul>
        <li><strong>ë¬¸ì œ ìœ í˜•</strong>: ì´ì§„ ë¶„ë¥˜ (Binary Classification)</li>
        <li><strong>íƒ€ê²Ÿ</strong>: Dropout(0) vs Graduate(1)</li>
        <li><strong>ëª©í‘œ</strong>: í•™ìƒì˜ ì¤‘ë„ ì´íƒˆ ê°€ëŠ¥ì„±ì„ ì‚¬ì „ì— ì˜ˆì¸¡í•˜ì—¬ ì¡°ê¸° ê°œì… ì§€ì›</li>
    </ul>

    <h3>1.2 í‰ê°€ ì§€í‘œ ì„ ì •</h3>

    <table>
        <thead>
            <tr>
                <th>ì§€í‘œ</th>
                <th>ì„ ì • ì´ìœ </th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>Accuracy</strong></td>
                <td>ì „ì²´ ì •í™•ë„ (ê¸°ë³¸ ì§€í‘œ)</td>
            </tr>
            <tr>
                <td><strong>Precision</strong></td>
                <td>Dropout ì˜ˆì¸¡ì˜ ì •ë°€ë„ (ì˜¤íƒ ìµœì†Œí™”)</td>
            </tr>
            <tr>
                <td><strong>Recall</strong></td>
                <td>ì‹¤ì œ Dropout í•™ìƒ íƒì§€ìœ¨ (ë†“ì¹¨ ìµœì†Œí™”)</td>
            </tr>
            <tr>
                <td><strong>F1-score</strong></td>
                <td>Precisionê³¼ Recallì˜ ì¡°í™”í‰ê·  (ì£¼ìš” ì§€í‘œ)</td>
            </tr>
            <tr>
                <td><strong>ROC-AUC</strong></td>
                <td>ë¶„ë¥˜ ì„±ëŠ¥ ì¢…í•© í‰ê°€</td>
            </tr>
        </tbody>
    </table>

    <p class="highlight"><strong>ìš°ì„ ìˆœìœ„</strong>: <strong>Recall > F1-score > Precision</strong><br>
    â†’ ì‹¤ì œ ì´íƒˆ ìœ„í—˜ í•™ìƒì„ ë†“ì¹˜ëŠ” ê²ƒì´ ë” í° ë¬¸ì œì´ë¯€ë¡œ Recallì„ ìš°ì„ ì‹œ</p>

    <hr>

    <h2>2. ì‹¤í—˜í•œ ëª¨ë¸</h2>

    <h3>2.1 ëª¨ë¸ ì„ ì • ê·¼ê±°</h3>

    <table>
        <thead>
            <tr>
                <th>ëª¨ë¸</th>
                <th>ì„ ì • ì´ìœ </th>
                <th>ì¥ì </th>
                <th>ë‹¨ì </th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>Logistic Regression</strong></td>
                <td>ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸</td>
                <td>í•´ì„ ìš©ì´, ë¹ ë¥¸ í•™ìŠµ</td>
                <td>ë¹„ì„ í˜• ê´€ê³„ í¬ì°© í•œê³„</td>
            </tr>
            <tr>
                <td><strong>Decision Tree</strong></td>
                <td>ë‹¨ìˆœ íŠ¸ë¦¬ ëª¨ë¸</td>
                <td>ì§ê´€ì , ì‹œê°í™” ê°€ëŠ¥</td>
                <td>ê³¼ì í•© ìœ„í—˜ ë†’ìŒ</td>
            </tr>
            <tr>
                <td><strong>Random Forest</strong></td>
                <td>ì•™ìƒë¸” (Bagging)</td>
                <td>ê³¼ì í•© ë°©ì§€, ë³€ìˆ˜ ì¤‘ìš”ë„ ì œê³µ</td>
                <td>í•™ìŠµ ì‹œê°„ ë‹¤ì†Œ ì†Œìš”</td>
            </tr>
            <tr>
                <td><strong>AdaBoost</strong></td>
                <td>ì•™ìƒë¸” (Boosting)</td>
                <td>ì•½í•œ í•™ìŠµê¸° ìˆœì°¨ ê°œì„ </td>
                <td>ë…¸ì´ì¦ˆì— ë¯¼ê°</td>
            </tr>
            <tr>
                <td><strong>XGBoost</strong></td>
                <td>ê³ ì„±ëŠ¥ Gradient Boosting</td>
                <td>ì •ê·œí™”, ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ë¹ ë¥¸ ì†ë„</td>
                <td>í•˜ì´í¼íŒŒë¼ë¯¸í„° ë§ìŒ</td>
            </tr>
            <tr>
                <td><strong>LightGBM</strong></td>
                <td>Leaf-wise Gradient Boosting</td>
                <td>ë¹ ë¥¸ í•™ìŠµ, ëŒ€ìš©ëŸ‰ ë°ì´í„° ì í•©</td>
                <td>ê³¼ì í•© ìœ„í—˜ (ì‘ì€ ë°ì´í„°)</td>
            </tr>
        </tbody>
    </table>

    <hr>

    <h2>3. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹</h2>

    <h3>3.1 íŠœë‹ ì „ëµ</h3>

    <h4>íƒìƒ‰ ë°©ë²•</h4>
    <ul>
        <li><strong>GridSearchCV</strong>: ì „ì²´ ì¡°í•© íƒìƒ‰ (ì‘ì€ íŒŒë¼ë¯¸í„° ê³µê°„)</li>
        <li><strong>RandomizedSearchCV</strong>: ë¬´ì‘ìœ„ ìƒ˜í”Œë§ (í° íŒŒë¼ë¯¸í„° ê³µê°„)</li>
        <li><strong>êµì°¨ ê²€ì¦</strong>: StratifiedKFold(n_splits=5)</li>
    </ul>

    <h4>í‰ê°€ ì§€í‘œ</h4>
    <ul>
        <li><strong>Scoring</strong>: F1-score (ì´ì§„ ë¶„ë¥˜ì—ì„œ ê· í˜• ì¡íŒ ì§€í‘œ)</li>
    </ul>

    <hr>

    <h3>3.2 ëª¨ë¸ë³„ íŠœë‹ ê²°ê³¼</h3>

    <h4>1) Logistic Regression</h4>
    <pre><code>param_grid = {
    'C': [0.01, 0.1, 1, 10, 100],
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear', 'saga'],
    'max_iter': [500, 1000]
}</code></pre>

    <p><strong>ìµœì  íŒŒë¼ë¯¸í„°</strong>:</p>
    <ul>
        <li>C: 1</li>
        <li>penalty: 'l2'</li>
        <li>solver: 'liblinear'</li>
    </ul>

    <hr>

    <h4>2) Decision Tree</h4>
    <pre><code>param_grid = {
    'max_depth': [5, 10, 15, 20, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'criterion': ['gini', 'entropy']
}</code></pre>

    <p><strong>ìµœì  íŒŒë¼ë¯¸í„°</strong>:</p>
    <ul>
        <li>max_depth: 15</li>
        <li>min_samples_split: 5</li>
        <li>min_samples_leaf: 2</li>
        <li>criterion: 'gini'</li>
    </ul>

    <hr>

    <h4>3) Random Forest (ìµœì¢… ì„ íƒ)</h4>
    <pre><code>param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 15, 20, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2']
}</code></pre>

    <p><strong>ìµœì  íŒŒë¼ë¯¸í„°</strong>:</p>
    <ul>
        <li>n_estimators: 200</li>
        <li>max_depth: 20</li>
        <li>min_samples_split: 2</li>
        <li>min_samples_leaf: 1</li>
        <li>max_features: 'sqrt'</li>
        <li>class_weight: 'balanced'</li>
    </ul>

    <hr>

    <h4>4) AdaBoost</h4>
    <pre><code>param_grid = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.1, 0.5, 1.0],
    'algorithm': ['SAMME', 'SAMME.R']
}</code></pre>

    <p><strong>ìµœì  íŒŒë¼ë¯¸í„°</strong>:</p>
    <ul>
        <li>n_estimators: 200</li>
        <li>learning_rate: 0.5</li>
        <li>algorithm: 'SAMME.R'</li>
    </ul>

    <hr>

    <h4>5) XGBoost</h4>
    <pre><code>param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7, 10],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'subsample': [0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.7, 0.8, 0.9, 1.0]
}</code></pre>

    <p><strong>ìµœì  íŒŒë¼ë¯¸í„°</strong>:</p>
    <ul>
        <li>n_estimators: 200</li>
        <li>max_depth: 5</li>
        <li>learning_rate: 0.1</li>
        <li>subsample: 0.8</li>
        <li>colsample_bytree: 0.8</li>
    </ul>

    <hr>

    <h4>6) LightGBM</h4>
    <pre><code>param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, 15, -1],
    'learning_rate': [0.01, 0.05, 0.1],
    'num_leaves': [31, 50, 70],
    'min_child_samples': [20, 30, 50]
}</code></pre>

    <p><strong>ìµœì  íŒŒë¼ë¯¸í„°</strong>:</p>
    <ul>
        <li>n_estimators: 200</li>
        <li>max_depth: 10</li>
        <li>learning_rate: 0.1</li>
        <li>num_leaves: 50</li>
        <li>min_child_samples: 20</li>
    </ul>

    <hr>

    <h2>4. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ</h2>

    <h3>4.1 ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½</h3>

    <table>
        <thead>
            <tr>
                <th>ëª¨ë¸</th>
                <th>Accuracy</th>
                <th>Precision</th>
                <th>Recall</th>
                <th>F1-score</th>
                <th>í•™ìŠµ ì‹œê°„</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>Random Forest</strong></td>
                <td><strong>0.9146</strong></td>
                <td><strong>0.8975</strong></td>
                <td><strong>0.9706</strong></td>
                <td><strong>0.9326</strong></td>
                <td>ì¤‘ê°„</td>
            </tr>
            <tr>
                <td>XGBoost</td>
                <td>0.9118</td>
                <td>0.9004</td>
                <td>0.9615</td>
                <td>0.9299</td>
                <td>ì¤‘ê°„</td>
            </tr>
            <tr>
                <td>AdaBoost</td>
                <td>0.9049</td>
                <td>0.8926</td>
                <td>0.9593</td>
                <td>0.9248</td>
                <td>ë¹ ë¦„</td>
            </tr>
            <tr>
                <td>LightGBM</td>
                <td>0.9036</td>
                <td>0.8924</td>
                <td>0.9570</td>
                <td>0.9236</td>
                <td>ë¹ ë¦„</td>
            </tr>
            <tr>
                <td>Decision Tree</td>
                <td>0.9008</td>
                <td>0.8854</td>
                <td>0.9615</td>
                <td>0.9219</td>
                <td>ë§¤ìš° ë¹ ë¦„</td>
            </tr>
            <tr>
                <td>Logistic Regression</td>
                <td>0.9008</td>
                <td>0.9093</td>
                <td>0.9299</td>
                <td>0.9195</td>
                <td>ë§¤ìš° ë¹ ë¦„</td>
            </tr>
        </tbody>
    </table>

    <hr>

    <h3>4.2 ìµœì¢… ëª¨ë¸ ì„ ì •: Random Forest</h3>

    <h4>ì„ ì • ê·¼ê±°</h4>
    <ol>
        <li><strong>ê°€ì¥ ë†’ì€ F1-score (0.9326)</strong>: Precisionê³¼ Recallì˜ ê· í˜•ì´ ê°€ì¥ ìš°ìˆ˜</li>
        <li><strong>ë†’ì€ Recall (0.9706)</strong>: ì‹¤ì œ Dropout í•™ìƒì˜ 97%ë¥¼ ì •í™•íˆ íƒì§€</li>
        <li><strong>ì•ˆì •ì ì¸ ì„±ëŠ¥</strong>: êµì°¨ ê²€ì¦ì—ì„œ ì¼ê´€ëœ ì„±ëŠ¥ ìœ ì§€</li>
        <li><strong>í•´ì„ ê°€ëŠ¥ì„±</strong>: Feature Importance ì œê³µìœ¼ë¡œ ì£¼ìš” ë³€ìˆ˜ ì‹ë³„ ê°€ëŠ¥</li>
        <li><strong>ê³¼ì í•© ë°©ì§€</strong>: ì•™ìƒë¸” ë°©ì‹ìœ¼ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ ìš°ìˆ˜</li>
    </ol>

    <hr>

    <h2>5. ìµœì¢… ëª¨ë¸ ìƒì„¸ ë¶„ì„</h2>

    <h3>5.1 Random Forest ëª¨ë¸ êµ¬ì¡°</h3>

    <pre><code>RandomForestClassifier(
    n_estimators=200,          # 200ê°œì˜ Decision Tree
    max_depth=20,              # ìµœëŒ€ ê¹Šì´ 20
    min_samples_split=2,       # ë…¸ë“œ ë¶„í•  ìµœì†Œ ìƒ˜í”Œ ìˆ˜
    min_samples_leaf=1,        # ë¦¬í”„ ë…¸ë“œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
    max_features='sqrt',       # ë¶„í•  ì‹œ ê³ ë ¤í•  íŠ¹ì§• ìˆ˜
    class_weight='balanced',   # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
    random_state=42,
    n_jobs=-1                  # ë³‘ë ¬ ì²˜ë¦¬
)</code></pre>

    <hr>

    <h3>5.2 í´ë˜ìŠ¤ë³„ ì„±ëŠ¥</h3>

    <h4>Confusion Matrix ë¶„ì„</h4>

    <table>
        <thead>
            <tr>
                <th></th>
                <th>ì˜ˆì¸¡: Graduate</th>
                <th>ì˜ˆì¸¡: Dropout</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>ì‹¤ì œ: Graduate</strong></td>
                <td>408 (TN)</td>
                <td>84 (FP)</td>
            </tr>
            <tr>
                <td><strong>ì‹¤ì œ: Dropout</strong></td>
                <td>7 (FN)</td>
                <td>227 (TP)</td>
            </tr>
        </tbody>
    </table>

    <h4>í´ë˜ìŠ¤ë³„ ì§€í‘œ</h4>

    <table>
        <thead>
            <tr>
                <th>í´ë˜ìŠ¤</th>
                <th>Precision</th>
                <th>Recall</th>
                <th>F1-score</th>
                <th>Support</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>Graduate (0)</strong></td>
                <td>0.95</td>
                <td>0.83</td>
                <td>0.88</td>
                <td>492</td>
            </tr>
            <tr>
                <td><strong>Dropout (1)</strong></td>
                <td>0.90</td>
                <td>0.97</td>
                <td>0.93</td>
                <td>234</td>
            </tr>
        </tbody>
    </table>

    <p class="highlight"><strong>í•´ì„</strong>:<br>
    - <strong>Graduate í´ë˜ìŠ¤</strong>: Precisionì´ ë†’ì•„ Graduateë¡œ ì˜ˆì¸¡í•˜ë©´ ì‹ ë¢°ë„ê°€ ë†’ìŒ<br>
    - <strong>Dropout í´ë˜ìŠ¤</strong>: Recallì´ 97%ë¡œ ì‹¤ì œ Dropout í•™ìƒì„ ê±°ì˜ ë†“ì¹˜ì§€ ì•ŠìŒ<br>
    - <strong>ì¡°ê¸° ê²½ë³´ ì‹œìŠ¤í…œ</strong>ì— ì í•©: Dropout íƒì§€ìœ¨ì´ ë†’ì•„ ìœ„í—˜ í•™ìƒ ì¡°ê¸° ë°œê²¬ ê°€ëŠ¥</p>

    <hr>

    <h3>5.3 í•™ìŠµ ê³¡ì„  (Learning Curve) ë¶„ì„</h3>

    <pre><code>Train Score: 0.9876
Test Score: 0.9146
ì°¨ì´: 0.0730</code></pre>

    <p><strong>ë¶„ì„</strong>:<br>
    - Trainê³¼ Test ì ìˆ˜ ì°¨ì´ê°€ ì•½ 7% ìˆ˜ì¤€<br>
    - ê²½ë¯¸í•œ ê³¼ì í•© ì¡´ì¬í•˜ë‚˜ í—ˆìš© ë²”ìœ„ ë‚´<br>
    - ë°ì´í„° ì¦ê°€ ì‹œ ì„±ëŠ¥ ê°œì„  ì—¬ì§€ ìˆìŒ</p>

    <hr>

    <h2>6. Feature Importance ë¶„ì„</h2>

    <p></p>

    <h3>6.1 ìƒìœ„ 20ê°œ ì¤‘ìš” ë³€ìˆ˜</h3>

    <table>
        <thead>
            <tr>
                <th>ìˆœìœ„</th>
                <th>ë³€ìˆ˜ëª…</th>
                <th>ì¤‘ìš”ë„</th>
                <th>í•´ì„</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>1</td>
                <td>Curricular units 2nd sem (grade)</td>
                <td>0.1523</td>
                <td>2í•™ê¸° í•™ì—… ì„±ì  (ìµœê³  ì¤‘ìš”ë„)</td>
            </tr>
            <tr>
                <td>2</td>
                <td>Curricular units 1st sem (grade)</td>
                <td>0.1407</td>
                <td>1í•™ê¸° í•™ì—… ì„±ì </td>
            </tr>
            <tr>
                <td>3</td>
                <td>Curricular units 2nd sem (approved)</td>
                <td>0.0892</td>
                <td>2í•™ê¸° ìŠ¹ì¸ ê³¼ëª© ìˆ˜</td>
            </tr>
            <tr>
                <td>4</td>
                <td>Curricular units 1st sem (approved)</td>
                <td>0.0854</td>
                <td>1í•™ê¸° ìŠ¹ì¸ ê³¼ëª© ìˆ˜</td>
            </tr>
            <tr>
                <td>5</td>
                <td>Tuition fees up to date</td>
                <td>0.0635</td>
                <td>ë“±ë¡ê¸ˆ ë‚©ë¶€ ìƒíƒœ</td>
            </tr>
            <tr>
                <td>6</td>